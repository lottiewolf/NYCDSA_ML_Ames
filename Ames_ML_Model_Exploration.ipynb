{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41aa43e4-8797-46a9-b2aa-d8454981bc21",
   "metadata": {},
   "source": [
    "# Ames Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe8f2d-f336-4e7b-8338-81e5638f1929",
   "metadata": {},
   "source": [
    "Load the dataset, begin modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7bda3f3-afa2-4ba5-807a-81a69cd0f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7abe5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#housing_nick = pd.read_csv('data/NH_DF.csv')\n",
    "#housing_cats = pd.read_csv('data/housing_with_cats.csv')\n",
    "housing = pd.read_csv('data/housing_numerical.csv')\n",
    "\n",
    "housing.drop('latitude',axis=1,inplace=True)\n",
    "housing.drop('longitude',axis=1,inplace=True)\n",
    "housing.drop('DateSold',axis=1,inplace=True)\n",
    "\n",
    "#housing.count()\n",
    "#housing.info()\n",
    "#housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bc0b70d-b9ee-4dd9-94eb-ef88bfcb5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 'None' for categorical columns, and fill NaN with 0 for numerical features.\n",
    "# Loop through each feature and examine\n",
    "for i, feature in enumerate(housing.columns):\n",
    "    if housing[feature].dtype=='object':\n",
    "        housing[feature]=housing[feature].fillna('None')\n",
    "        #print(i,feature,housing[feature].unique())\n",
    "        #print(i)\n",
    "    else:\n",
    "        h_mean = housing[feature].mean()\n",
    "        housing[feature] = housing[feature].fillna(h_mean)\n",
    "        #print(housing[feature].describe())\n",
    "        #print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b3320-658f-4a60-b00c-4662c437fa0d",
   "metadata": {},
   "source": [
    "# Simple Linear Regression (SLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65bbe390-088c-4a07-a067-60bd81a035f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLR(X, y):\n",
    "    #Set up the model\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, y)\n",
    "    score=lm.score(X, y)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc99a1-261e-4901-a4dd-df9022c0e9ba",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression (MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "73135282-b7e1-453d-8e4b-417d7f4c66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLR(X, y):\n",
    "    # Split the dataset into a training set and a test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred = lm.predict(X_test) # Make predictions on the test set\n",
    "    r2_value_calculated = r2_score(y_test, y_pred)\n",
    "    coef = lm.coef_\n",
    "    return [r2_value_calculated, coef]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd799e53-a2fd-4916-87c3-d7c430b1c7b2",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression (MLR) with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "812ca9ba-d701-4e3d-b70b-da9e2aa536f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLR_kfold(X,y,k):\n",
    "    # Create an instance of KFold with the desired number of folds\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize lists to store RMSE and R-squared values for each fold\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # 2. Modeling (MLR)\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        y_pred = lm.predict(X_test) # Make predictions on the test set\n",
    "        \n",
    "        # 3. Evaluation Calculate MAE, MSE, and RMSE for this fold\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the scores to the respective lists\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        print(i,\"R-squared:\", r2)\n",
    "        i=i+1\n",
    "\n",
    "    return [rmse_scores, r2_scores]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4fa37c-4051-4a16-9867-f06d2ef1eea7",
   "metadata": {},
   "source": [
    "# Penalized Regression with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4dfb7e7-4082-4b3c-9efc-378f97b8aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions do penalized regression on ridge, lasso, and elastic net\n",
    "# regression models with k-fold cross validation, and uses GridSearchCV to \n",
    "# determine the best alpha\n",
    "\n",
    "def grid_alpha(X,y,model):\n",
    "    # Do GridSearchCV to find best alpha\n",
    "    params = {'alpha': np.linspace(0, 1, 5)}\n",
    "    grid = GridSearchCV(model, params, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    gX_train, gX_test, gy_train, gy_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    gX_train = StandardScaler().fit_transform(gX_train)\n",
    "    gX_train = pd.DataFrame(gX_train)\n",
    "    \n",
    "    grid.fit(gX_train, gy_train)\n",
    "    best_alpha = grid.best_params_['alpha']\n",
    "    print(\"best alpha for \",model,\": \",best_alpha)\n",
    "    return best_alpha\n",
    "    \n",
    "def penalized(X,y,k,ratio):\n",
    "    print(\"Ridge, Lasso, and Elastic Net with GridSearchCV for alpha\")\n",
    "    print(\"Features:\\n\", list(X.columns.values))\n",
    "\n",
    "    ridge_alpha = grid_alpha(X,y, Ridge())\n",
    "    lasso_alpha = grid_alpha(X,y, Lasso())\n",
    "    enet_alpha = grid_alpha(X,y, ElasticNet())\n",
    "       \n",
    "    # Create an instance of KFold with the desired number of folds, iterate\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train_s = scaler.transform(X_train)\n",
    "        X_train_s = pd.DataFrame(X_train_s)\n",
    "\n",
    "        ############################ Create Models ###########################################     \n",
    "        ridge_model = Ridge(alpha=ridge_alpha) \n",
    "        lasso_model = Lasso(alpha=lasso_alpha)\n",
    "        elasticnet_model = ElasticNet(alpha=enet_alpha, l1_ratio=ratio) # Ratio mixing parameter controls balance between Ridge and Lasso\n",
    "    \n",
    "        # Fit the models on the training data\n",
    "        ridge_model.fit(X_train_s, y_train)\n",
    "        lasso_model.fit(X_train_s, y_train)\n",
    "        elasticnet_model.fit(X_train_s, y_train)\n",
    "    \n",
    "        ######################### Make predictions using models #############################\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "        X_test_s = pd.DataFrame(X_test_s)\n",
    "        ridge_predictions = ridge_model.predict(X_test_s)\n",
    "        lasso_predictions = lasso_model.predict(X_test_s)\n",
    "        elasticnet_predictions = elasticnet_model.predict(X_test_s)\n",
    "    \n",
    "        ############################ Evaluate Models #########################################\n",
    "        # Calculate R-squared for the models\n",
    "        ridge_r2 = r2_score(y_test, ridge_predictions)\n",
    "        lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "        elasticnet_r2 = r2_score(y_test, elasticnet_predictions)\n",
    "    \n",
    "        print(\"R-squared for Ridge model:\", ridge_r2)\n",
    "        print(\"R-squared for Lasso model:\", lasso_r2)\n",
    "        print(\"R-squared for ElasticNet model:\", elasticnet_r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab670454-25f5-464d-85e8-b31f700de192",
   "metadata": {},
   "source": [
    "# Running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a4f50-6df3-4bb6-82b6-c21c655d8aed",
   "metadata": {},
   "source": [
    "## Running Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8e1e2d9-cff9-4a17-834a-6d8dd9d0dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for the top 10 Simple Linear Regression models: \n",
      "score, feature\n",
      " [[1.0, 'SalePrice'], [0.6798715958383224, 'TotalSF'], [0.6298616937506346, 'OverallQual'], [0.5204328184549516, 'GrLivArea'], [0.46774549979837465, 'ExterQual'], [0.43177063751011224, 'KitchenQual'], [0.4283448377541429, 'TotalBsmtSF'], [0.4154510111295472, 'BsmtQual'], [0.4154213603034195, '1stFlrSF'], [0.4120791972028769, 'GarageCars']]\n"
     ]
    }
   ],
   "source": [
    "# Run SLR for all of the variables (non-nominal)\n",
    "\n",
    "#remove categorical non numeric features\n",
    "housing_num = housing.select_dtypes(exclude=[object])\n",
    "features = list(housing_num.columns.values)\n",
    "\n",
    "results = []\n",
    "# Loop through each feature and examine the score\n",
    "for i, feature in enumerate(housing[features]):\n",
    "    X=housing[[features[i]]]\n",
    "    y=housing['SalePrice']\n",
    "    score=SLR(X,y)\n",
    "    results.append([score,feature])\n",
    "\n",
    "results.sort(reverse=True)\n",
    "print(\"R2 for the top 10 Simple Linear Regression models: \\nscore, feature\\n\", results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f1b63-b037-4366-a6ab-f392a3b044b0",
   "metadata": {},
   "source": [
    "## Running Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e350d80f-21e7-4632-9671-4e69dd36ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GrLivArea', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'Age', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'LowQualFinSF', 'BedroomAbvGr']\n",
      "R2 for Multiple Linear Regression model:  0.8649311612533718\n",
      "Coefficient: [ 6.83147292e+01 -9.36749703e+02  2.82851291e+01  7.10371974e-01\n",
      "  1.57501567e+04  4.90140681e+03 -3.30065923e+02  2.13539994e+02\n",
      "  3.76511543e+01  2.11208137e+01  1.13389184e+01 -3.25206899e+00\n",
      "  2.92076632e+01 -1.76731942e+01 -9.61122618e+03]\n"
     ]
    }
   ],
   "source": [
    "best15_features = ['GrLivArea', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "            'Age', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "            'LowQualFinSF', 'BedroomAbvGr'] #top 15 from one of the combinatorics run\n",
    "X = housing[best15_features]  # Features\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "r = MLR(X,y)\n",
    "print(best15_features)\n",
    "print(\"R2 for Multiple Linear Regression model: \", r[0])\n",
    "print(\"Coefficient:\", r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f83e780-fbff-4f6e-a750-d6f32b747dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR with k-fold Cross Validation\n",
      "Features:\n",
      " ['TotalSF', 'Age']\n",
      "0 R-squared: 0.748909898301216\n",
      "1 R-squared: 0.759749861919766\n",
      "2 R-squared: 0.7618708846412267\n",
      "3 R-squared: 0.754905357875141\n",
      "4 R-squared: 0.7065066069288354\n",
      "Average R-squared: 0.7463885219332369\n",
      "Standard deviation of R-squared: 0.020433746298346732\n"
     ]
    }
   ],
   "source": [
    "# Run MLR with K-fold CV\n",
    "\n",
    "# MLR with K-fold Cross Validation\n",
    "features = ['TotalSF','Age']\n",
    "X = housing[features]  # Features\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "print(\"MLR with k-fold Cross Validation\")\n",
    "print(\"Features:\\n\", features)\n",
    "\n",
    "r = MLR_kfold(X,y,k=5)\n",
    "\n",
    "#print(\"Average RMSE:\", avg_rmse)\n",
    "print(\"Average R-squared:\", np.mean(r[1]))\n",
    "print(\"Standard deviation of R-squared:\", np.std(r[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f8e79-906c-419b-bd36-b66296ade1f3",
   "metadata": {},
   "source": [
    "## Running Ridge, Lasso, and Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "440d72fc-cda4-4ef8-9df6-ce104a0d9676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge, Lasso, and Elastic Net with GridSearchCV for alpha\n",
      "Features:\n",
      " ['GrLivArea', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'Age', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'LowQualFinSF', 'BedroomAbvGr']\n",
      "best alpha for  Ridge() :  1.0\n",
      "best alpha for  Lasso() :  1.0\n",
      "best alpha for  ElasticNet() :  0.0\n",
      "R-squared for Ridge model: 0.8649135069063798\n",
      "R-squared for Lasso model: 0.864930659918806\n",
      "R-squared for ElasticNet model: 0.8649311612533729\n",
      "R-squared for Ridge model: 0.85913503805854\n",
      "R-squared for Lasso model: 0.8591459351585524\n",
      "R-squared for ElasticNet model: 0.8591470005336064\n",
      "R-squared for Ridge model: 0.8643332384953831\n",
      "R-squared for Lasso model: 0.8643092226447522\n",
      "R-squared for ElasticNet model: 0.86430421668427\n",
      "R-squared for Ridge model: 0.8743256069421269\n",
      "R-squared for Lasso model: 0.8743209107455423\n",
      "R-squared for ElasticNet model: 0.8743188582203933\n",
      "R-squared for Ridge model: 0.8598856588949221\n",
      "R-squared for Lasso model: 0.8598727720636453\n",
      "R-squared for ElasticNet model: 0.8598759447119011\n"
     ]
    }
   ],
   "source": [
    "X = housing[best15_features]  # Features\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "penalized(X,y,k=5,ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd734656-bb22-46ed-a5fd-d9fcdad68a67",
   "metadata": {},
   "source": [
    "## Running categorical var for Vinod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2aa1f92-b954-4628-9531-f4db3c4044fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TotalSF', 'Neighborhood']\n",
      "R2 for Multiple Linear Regression model:  0.7912020836411895\n",
      "Coefficient: [5.96965002e+01 1.80183691e+04 2.46125247e+03 6.10022937e+03\n",
      " 3.09357870e+04 4.39267752e+04 3.20400792e+04 1.13479667e+05\n",
      " 1.77133054e+04 5.17372451e+04 3.94660442e+04 7.77843590e+03\n",
      " 1.60107170e+04 5.07121232e+04 6.80960598e+04 7.65711865e+04\n",
      " 1.69979413e+04 1.02166957e+05 2.11279580e+04 5.09140860e+04\n",
      " 6.80456047e+04 4.86559995e+04 1.63450113e+05 1.11956439e+05\n",
      " 6.42902050e+04 2.26043553e+04 4.25261425e+04 3.13489049e+04]\n"
     ]
    }
   ],
   "source": [
    "# Run MLR for Vinod's question about categorical variables\n",
    "\n",
    "#features = ['TotalSF','Age']\n",
    "#features = ['TotalSF','OverallQual']\n",
    "features = ['TotalSF','Neighborhood']\n",
    "X = housing[features]  # Features\n",
    "\n",
    "# Convert categorical columns to one-hot encoding\n",
    "X = pd.get_dummies(X, columns=['Neighborhood'], drop_first=True)\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "r = MLR(X,y)\n",
    "print(features)\n",
    "print(\"R2 for Multiple Linear Regression model: \", r[0])\n",
    "print(\"Coefficient:\", r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ec060-bb22-4ecf-b349-ec079d8145bc",
   "metadata": {},
   "source": [
    "## Results for Vinod's Question Regarding Categorical Variables\n",
    "3. \n",
    "\n",
    "    A) using 2 numerical features.\n",
    "   \n",
    "    MLR with k-fold Cross Validation\n",
    "    Features:\n",
    "     ['TotalSF', 'YearBuilt']\n",
    "    0 R-squared: 0.7416625031183677\n",
    "    1 R-squared: 0.7217569726901124\n",
    "    2 R-squared: 0.7396252336514776\n",
    "    3 R-squared: 0.7284613561793205\n",
    "    4 R-squared: 0.7450915795474258\n",
    "    Average R-squared: 0.7353195290373409\n",
    "    Standard deviation of R-squared: 0.008777731520280862\n",
    "\n",
    "    ['TotalSF', 'YearBuilt']\n",
    "    R2 for Multiple Linear Regression model:  0.7416625031183677\n",
    "    Coefficient: [ 70.20861997 706.57551685]\n",
    "\n",
    "    B) One using 1 numerical + 1 ordinal (categorial)\n",
    "\n",
    "    MLR with k-fold Cross Validation\n",
    "    Features:\n",
    "     ['TotalSF', 'OverallQual']\n",
    "    0 R-squared: 0.792774534309626\n",
    "    1 R-squared: 0.7624705587335859\n",
    "    2 R-squared: 0.7877980662360704\n",
    "    3 R-squared: 0.7687533574218369\n",
    "    4 R-squared: 0.8070790469236628\n",
    "    Average R-squared: 0.7837751127249565\n",
    "    Standard deviation of R-squared: 0.01624674888158771\n",
    "\n",
    "    ['TotalSF', 'OverallQual']\n",
    "    R2 for Multiple Linear Regression model:  0.792774534309626\n",
    "    Coefficient: [   51.60485606 24634.19345553]\n",
    "\n",
    "    C) One using 1 numerical + 1 nominal (categorical)\n",
    "\n",
    "    ['TotalSF', 'Neighborhood']\n",
    "    R2 for Multiple Linear Regression model:  0.7752658566982651\n",
    "    Coefficient: [ 5.85357913e+01 -1.44534936e+04 -3.07217621e+04 -2.92747827e+04\n",
    "     -4.59607469e+03  6.31958875e+03  1.76623599e+03 -3.17566089e+04\n",
    "      4.64969094e+03  2.13902795e+04  1.15656923e+05 -4.11100342e+04\n",
    "     -1.56651870e+04 -3.97234514e+04 -1.44459331e+04 -2.93749044e+04\n",
    "     -2.54999577e+04 -1.80343378e+04  6.29015223e+04  6.86566889e+04\n",
    "     -4.12164036e+04 -4.47433094e+04 -2.49892035e+04 -4.02619715e+03\n",
    "      2.83089424e+04  6.73020370e+04  2.10537330e+04  1.83914854e+04]\n",
    "\n",
    "    MLR with k-fold Cross Validation\n",
    "    Features:\n",
    "     ['TotalSF', 'Neighborhood']\n",
    "    0 R-squared: 0.775265856698265\n",
    "    1 R-squared: 0.7993892323818912\n",
    "    2 R-squared: 0.7863056427419447\n",
    "    3 R-squared: 0.7871833976141214\n",
    "    4 R-squared: 0.7807599813736235\n",
    "    Average R-squared: 0.7857808221619691\n",
    "    Standard deviation of R-squared: 0.008039960499637195\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096aa9d-d163-486b-bbed-07fe5070eeef",
   "metadata": {},
   "source": [
    "##  Multiple Linear Regression using Combinatorics for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e7ed548c-0eaa-4611-a74f-c7344c1d5e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 81\n",
      "66 uncertain features\n",
      "Looking at using  65  of these features\n",
      "R2: 0.8844795924879507 Feature found to drop ['BldgType']\n",
      "Looking at using  64  of these features\n",
      "R2: 0.8812016615325675 Feature found to drop ['OverallCond']\n",
      "Looking at using  63  of these features\n",
      "R2: 0.8772305234981039 Feature found to drop ['Functional']\n",
      "Looking at using  62  of these features\n",
      "R2: 0.875224671058177 Feature found to drop ['ScreenPorch']\n",
      "Looking at using  61  of these features\n",
      "R2: 0.873164446142345 Feature found to drop ['MSZoning']\n",
      "Looking at using  60  of these features\n",
      "R2: 0.8711313542959633 Feature found to drop ['KitchenAbvGr']\n",
      "Looking at using  59  of these features\n",
      "R2: 0.8703694224502999 Feature found to drop ['Bath']\n",
      "Looking at using  58  of these features\n",
      "R2: 0.8696120501704416 Feature found to drop ['Exterior1st']\n",
      "Looking at using  57  of these features\n",
      "R2: 0.8689255795639927 Feature found to drop ['MSSubClass']\n",
      "Looking at using  56  of these features\n",
      "R2: 0.8675336145530899 Feature found to drop ['BedroomAbvGr']\n",
      "Looking at using  55  of these features\n",
      "R2: 0.8662214894048825 Feature found to drop ['MiscRmsAbvGrd']\n",
      "Looking at using  54  of these features\n",
      "R2: 0.8651478509575817 Feature found to drop ['Fireplaces']\n",
      "Looking at using  53  of these features\n",
      "R2: 0.8640742626528878 Feature found to drop ['MA_Zip1']\n",
      "Looking at using  52  of these features\n",
      "R2: 0.8629166554787191 Feature found to drop ['Condition1']\n",
      "Looking at using  51  of these features\n",
      "R2: 0.8622376031783027 Feature found to drop ['FireplaceQu']\n",
      "Looking at using  50  of these features\n",
      "R2: 0.8617345520669875 Feature found to drop ['RoofStyle']\n",
      "Looking at using  49  of these features\n",
      "R2: 0.861306198986589 Feature found to drop ['Alley']\n",
      "Looking at using  48  of these features\n",
      "R2: 0.8608520099254522 Feature found to drop ['WoodDeckSF']\n",
      "Looking at using  47  of these features\n",
      "R2: 0.8604645186625091 Feature found to drop ['ExterCond']\n",
      "Looking at using  46  of these features\n",
      "R2: 0.8600711433973287 Feature found to drop ['Condition2']\n",
      "Looking at using  45  of these features\n",
      "R2: 0.8597572260107742 Feature found to drop ['MasVnrType']\n",
      "Looking at using  44  of these features\n",
      "R2: 0.8594867955196249 Feature found to drop ['DistanceToISU']\n",
      "Looking at using  43  of these features\n",
      "R2: 0.8592333193297791 Feature found to drop ['GarageType']\n",
      "Looking at using  42  of these features\n",
      "R2: 0.8590438501034605 Feature found to drop ['HouseStyle']\n",
      "Looking at using  41  of these features\n",
      "R2: 0.8589256539171125 Feature found to drop ['HeatingQC']\n",
      "Looking at using  40  of these features\n",
      "R2: 0.8587341796767305 Feature found to drop ['BsmtFinType2']\n",
      "Looking at using  39  of these features\n",
      "R2: 0.8586553435308986 Feature found to drop ['MiscFeature']\n",
      "Looking at using  38  of these features\n",
      "R2: 0.8586086649339328 Feature found to drop ['GarageCond']\n",
      "Looking at using  37  of these features\n",
      "R2: 0.858541553253109 Feature found to drop ['Heating']\n",
      "Looking at using  36  of these features\n",
      "R2: 0.8585164641509653 Feature found to drop ['LotConfig']\n",
      "Looking at using  35  of these features\n",
      "R2: 0.8584951945408139 Feature found to drop ['Street']\n",
      "Looking at using  34  of these features\n",
      "R2: 0.858485987722653 Feature found to drop ['GarageQual']\n",
      "Looking at using  33  of these features\n",
      "R2: 0.8584854351361605 Feature found to drop ['BsmtCond']\n",
      "Looking at using  32  of these features\n",
      "R2: 0.8584854351361381 Feature found to drop ['TotalBsmtSF']\n",
      "Looking at using  31  of these features\n",
      "R2: 0.8584854351361495 Feature found to drop ['BsmtFinSF2']\n",
      "Looking at using  30  of these features\n",
      "R2: 0.8584854351361664 Feature found to drop ['LowQualFinSF']\n",
      "Looking at using  29  of these features\n",
      "R2: 0.8582384302608806 Feature found to drop ['2ndFlrSF']\n",
      "Looking at using  28  of these features\n",
      "R2: 0.8582275163554614 Feature found to drop ['Electrical']\n",
      "Looking at using  27  of these features\n",
      "R2: 0.8582275163554596 Feature found to drop ['YearsSinceRemod']\n",
      "Looking at using  26  of these features\n",
      "R2: 0.8582285048093742 Feature found to drop ['OpenPorchSF']\n",
      "Looking at using  25  of these features\n",
      "R2: 0.858233265566118 Feature found to drop ['MiscVal']\n",
      "Looking at using  24  of these features\n",
      "R2: 0.8582384794664067 Feature found to drop ['GarageFinish']\n",
      "Looking at using  23  of these features\n",
      "R2: 0.8582465444757736 Feature found to drop ['BsmtBath']\n",
      "Looking at using  22  of these features\n",
      "R2: 0.8582888260688322 Feature found to drop ['3SsnPorch']\n",
      "Looking at using  21  of these features\n",
      "R2: 0.8583656141437843 Feature found to drop ['Fence']\n",
      "Looking at using  20  of these features\n",
      "R2: 0.8584375238057779 Feature found to drop ['CentralAir']\n",
      "Looking at using  19  of these features\n",
      "R2: 0.858518855040968 Feature found to drop ['EnclosedPorch']\n",
      "Looking at using  18  of these features\n",
      "R2: 0.8586387655434946 Feature found to drop ['PavedDrive']\n",
      "Looking at using  17  of these features\n",
      "R2: 0.8587489441094371 Feature found to drop ['Foundation']\n",
      "Looking at using  16  of these features\n",
      "R2: 0.8588323315617146 Feature found to drop ['BsmtFinType1']\n",
      "Looking at using  15  of these features\n",
      "R2: 0.8589603635216236 Feature found to drop ['MoSold']\n",
      "Looking at using  14  of these features\n",
      "R2: 0.8590889373223554 Feature found to drop ['Exterior2nd']\n",
      "Looking at using  13  of these features\n",
      "R2: 0.8592885413802983 Feature found to drop ['GarageYrBlt']\n",
      "Looking at using  12  of these features\n",
      "R2: 0.8595271097702726 Feature found to drop ['DistanceCategory']\n",
      "Looking at using  11  of these features\n",
      "R2: 0.8597441834415396 Feature found to drop ['LandSlope']\n",
      "Looking at using  10  of these features\n",
      "R2: 0.8599910400907469 Feature found to drop ['LandContour']\n",
      "Looking at using  9  of these features\n",
      "R2: 0.8605714741836816 Feature found to drop ['BsmtExposure']\n",
      "Looking at using  8  of these features\n",
      "R2: 0.8610541884833879 Feature found to drop ['LotFrontage']\n",
      "Looking at using  7  of these features\n",
      "R2: 0.8616050459537831 Feature found to drop ['LotShape']\n",
      "Looking at using  6  of these features\n",
      "R2: 0.862270514059107 Feature found to drop ['SaleCondition']\n",
      "Looking at using  5  of these features\n",
      "R2: 0.86340310700179 Feature found to drop ['YrSold']\n",
      "Looking at using  4  of these features\n",
      "R2: 0.8650179431404084 Feature found to drop ['BsmtUnfSF']\n",
      "Looking at using  3  of these features\n",
      "R2: 0.8676165279251558 Feature found to drop ['RoofMatl']\n",
      "Looking at using  2  of these features\n",
      "R2: 0.8701149117283761 Feature found to drop ['SaleType']\n",
      "Looking at using  1  of these features\n",
      "R2: 0.874469889119818 Feature found to drop ['PoolQC']\n",
      "Last remaining feature ['GrLivArea', 'LotArea', 'Neighborhood', 'OverallQual', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'BsmtQual', 'BsmtFinSF1', '1stFlrSF', 'KitchenQual', 'GarageCars', 'GarageArea', 'PoolArea', 'Age', 'TotalSF']\n"
     ]
    }
   ],
   "source": [
    "# Run MLR for all combinations of features to determine the best combi\n",
    "\n",
    "#remove categorical non numeric features\n",
    "housing_num = housing.select_dtypes(exclude=[object])\n",
    "features = list(housing_num.columns.values)\n",
    "features.remove('SalePrice')\n",
    "feature_list = features.copy()\n",
    "print(\"Total features:\",len(features))\n",
    "\n",
    "mutual_best = ['TotalSF', 'OverallQual', 'GrLivArea', 'ExterQual', 'GarageCars', \n",
    "               'Age','KitchenQual','GarageArea','BsmtFinSF1','1stFlrSF','BsmtQual',\n",
    "               'LotArea','MasVnrArea','YearRemodAdd','Neighborhood']\n",
    "features_unkwn = [ elem for elem in features if elem not in mutual_best]\n",
    "print(len(features_unkwn), \"uncertain features\")\n",
    "\n",
    "# Get all R2s of models with one fewer feature, find the best R2, remove lowest feature, repeat\n",
    "while len(features_unkwn)>1:\n",
    "    print(\"Looking at using \",len(features_unkwn)-1, \" of these features\")\n",
    "    comb = combinations(features_unkwn, len(features_unkwn)-1)\n",
    "    results = {}\n",
    "    #Get all r2 of all combinations of one fewer features\n",
    "    for c in comb:\n",
    "        mutual_best_plus = mutual_best.copy()\n",
    "        mutual_best_plus.extend(c)\n",
    "        X = housing[mutual_best_plus]  # Features\n",
    "        y = housing['SalePrice']  # Target variable\n",
    "        r = MLR(X, y)\n",
    "        results[r[0]] = mutual_best_plus\n",
    "\n",
    "    #Sort list of r2s, find best r2, find feature that was not included, drop that feature\n",
    "    r2s = list(results.keys())\n",
    "    r2s.sort()\n",
    "    best_features = results[r2s[0]]\n",
    "    feature_to_drop = [ elem for elem in feature_list if elem not in best_features]\n",
    "    print(\"R2:\",r2s[0],\"Feature found to drop\",feature_to_drop)\n",
    "    features_unkwn.remove(feature_to_drop[0])\n",
    "    feature_list.remove(feature_to_drop[0])\n",
    "print(\"Last remaining feature\",feature_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed72c40-5239-4ca5-aa83-8d1b56b9b899",
   "metadata": {},
   "source": [
    "# LazyPredict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7755fde0-83c4-4430-9e2e-3a58e5456203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:04,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8221848784876566, 'Adjusted R-Squared': 0.8168504248422863, 'RMSE': 31108.16551917727, 'Time taken': 0.13780856132507324}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8838160473707461, 'Adjusted R-Squared': 0.8803305287918686, 'RMSE': 25145.665222492247, 'Time taken': 0.11237525939941406}\n",
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8648424226588634, 'Adjusted R-Squared': 0.8607876953386293, 'RMSE': 27121.2845291356, 'Time taken': 0.008424043655395508}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7751534888595866, 'Adjusted R-Squared': 0.7684080935253742, 'RMSE': 34981.07343739264, 'Time taken': 0.024670839309692383}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -4.298010936176766e-05, 'Adjusted R-Squared': -0.030044269512642607, 'RMSE': 73773.33020994296, 'Time taken': 0.004591703414916992}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.8273110541205199, 'Adjusted R-Squared': 0.8221303857441354, 'RMSE': 30656.482648203473, 'Time taken': 0.0058596134185791016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:01, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.08644121052193654, 'Adjusted R-Squared': 0.05903444683759462, 'RMSE': 70511.23247140569, 'Time taken': 0.0579988956451416}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7898625743023164, 'Adjusted R-Squared': 0.7835584515313859, 'RMSE': 33817.52030214012, 'Time taken': 0.013492822647094727}\n",
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.8952214573763881, 'Adjusted R-Squared': 0.8920781010976798, 'RMSE': 23879.555165083184, 'Time taken': 0.4698781967163086}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:04,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GammaRegressor', 'R-Squared': 0.8062279375565905, 'Adjusted R-Squared': 0.8004147756832882, 'RMSE': 32473.98879609676, 'Time taken': 0.33382439613342285}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -0.3295026863105268, 'Adjusted R-Squared': -0.36938776689984265, 'RMSE': 85061.81891919838, 'Time taken': 0.2041771411895752}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:01<00:05,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.9176864307700451, 'Adjusted R-Squared': 0.9152170236931464, 'RMSE': 21165.365493490768, 'Time taken': 0.3439507484436035}\n",
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9146020290572757, 'Adjusted R-Squared': 0.912040089928994, 'RMSE': 21558.266266883504, 'Time taken': 0.16571617126464844}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▍                          | 16/42 [00:02<00:03,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HuberRegressor', 'R-Squared': 0.856578411031305, 'Adjusted R-Squared': 0.8522757633622442, 'RMSE': 27938.12914079551, 'Time taken': 0.04753708839416504}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.855972635890937, 'Adjusted R-Squared': 0.8516518149676651, 'RMSE': 27997.068631687885, 'Time taken': 0.028217315673828125}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -4.939760736564087, 'Adjusted R-Squared': -5.11795355866101, 'RMSE': 179793.72538715234, 'Time taken': 0.11210751533508301}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8649311612533728, 'Adjusted R-Squared': 0.860879096090974, 'RMSE': 27112.37973858692, 'Time taken': 0.009710311889648438}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8646562498030567, 'Adjusted R-Squared': 0.8605959372971483, 'RMSE': 27139.95721296858, 'Time taken': 0.02459549903869629}\n",
      "{'Model': 'Lasso', 'R-Squared': 0.864930659918806, 'Adjusted R-Squared': 0.8608785797163702, 'RMSE': 27112.43005500581, 'Time taken': 0.0086822509765625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▍                      | 20/42 [00:02<00:01, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoCV', 'R-Squared': 0.8644181724971434, 'Adjusted R-Squared': 0.8603507176720577, 'RMSE': 27163.817084176084, 'Time taken': 0.0641927719116211}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8649299132111413, 'Adjusted R-Squared': 0.8608778106074756, 'RMSE': 27112.504998110362, 'Time taken': 0.008332014083862305}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8646562498030567, 'Adjusted R-Squared': 0.8605959372971483, 'RMSE': 27139.95721296858, 'Time taken': 0.02404952049255371}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8649311612533728, 'Adjusted R-Squared': 0.860879096090974, 'RMSE': 27112.37973858692, 'Time taken': 0.01541280746459961}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8651892474643518, 'Adjusted R-Squared': 0.8611449248882823, 'RMSE': 27086.46451934868, 'Time taken': 0.006701231002807617}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -5.701626983869915, 'Adjusted R-Squared': -5.902675793386013, 'RMSE': 190976.61053131366, 'Time taken': 0.007030010223388672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 28/42 [00:03<00:01,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -5.616165801876334, 'Adjusted R-Squared': -5.814650775932624, 'RMSE': 189755.00761236297, 'Time taken': 0.9598965644836426}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.010879873690596398, 'Adjusted R-Squared': -0.04120626990131426, 'RMSE': 74171.97283873353, 'Time taken': 0.1244955062866211}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.6060347232801243, 'Adjusted R-Squared': 0.594215764978528, 'RMSE': 46304.055338959646, 'Time taken': 0.006014347076416016}\n",
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8299457522370165, 'Adjusted R-Squared': 0.8248441248041269, 'RMSE': 30421.72232045697, 'Time taken': 0.017815828323364258}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.8541489325664607, 'Adjusted R-Squared': 0.8497734005434545, 'RMSE': 28173.76329993604, 'Time taken': 0.038049936294555664}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▋           | 31/42 [00:04<00:02,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.9127143685800332, 'Adjusted R-Squared': 0.9100957996374341, 'RMSE': 21795.22890595133, 'Time taken': 1.065063238143921}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': 0.8407023547452894, 'Adjusted R-Squared': 0.8359234253876481, 'RMSE': 29443.85929431575, 'Time taken': 0.06969475746154785}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▊        | 34/42 [00:05<00:01,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.8950705334588199, 'Adjusted R-Squared': 0.8919226494625845, 'RMSE': 23896.747135176443, 'Time taken': 1.05271577835083}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8649135069063798, 'Adjusted R-Squared': 0.8608609121135712, 'RMSE': 27114.151559994767, 'Time taken': 0.008173704147338867}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.8647442248640107, 'Adjusted R-Squared': 0.860686551609931, 'RMSE': 27131.135130266804, 'Time taken': 0.0076711177825927734}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8658374834723963, 'Adjusted R-Squared': 0.8618126079765682, 'RMSE': 27021.26356330245, 'Time taken': 0.011515378952026367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:05<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.05935824312909177, 'Adjusted R-Squared': -0.09113899042296447, 'RMSE': 75929.66447285078, 'Time taken': 0.17586445808410645}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8651892474643518, 'Adjusted R-Squared': 0.8611449248882823, 'RMSE': 27086.46451934868, 'Time taken': 0.008521795272827148}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:06<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.7866930984251914, 'Adjusted R-Squared': 0.7802938913779471, 'RMSE': 34071.59849416967, 'Time taken': 0.6532449722290039}\n",
      "{'Model': 'XGBRegressor', 'R-Squared': 0.9120290735103294, 'Adjusted R-Squared': 0.9093899457156392, 'RMSE': 21880.62074291825, 'Time taken': 0.08388519287109375}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177730.119845\n",
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.9135665320106376, 'Adjusted R-Squared': 0.9109735279709568, 'RMSE': 21688.575317407227, 'Time taken': 0.08411121368408203}\n",
      "                               Adjusted R-Squared  R-Squared      RMSE  \\\n",
      "Model                                                                    \n",
      "GradientBoostingRegressor                    0.92       0.92  21165.37   \n",
      "HistGradientBoostingRegressor                0.91       0.91  21558.27   \n",
      "LGBMRegressor                                0.91       0.91  21688.58   \n",
      "PoissonRegressor                             0.91       0.91  21795.23   \n",
      "XGBRegressor                                 0.91       0.91  21880.62   \n",
      "ExtraTreesRegressor                          0.89       0.90  23879.56   \n",
      "RandomForestRegressor                        0.89       0.90  23896.75   \n",
      "BaggingRegressor                             0.88       0.88  25145.67   \n",
      "SGDRegressor                                 0.86       0.87  27021.26   \n",
      "TransformedTargetRegressor                   0.86       0.87  27086.46   \n",
      "LinearRegression                             0.86       0.87  27086.46   \n",
      "Lars                                         0.86       0.86  27112.38   \n",
      "LassoLarsIC                                  0.86       0.86  27112.38   \n",
      "Lasso                                        0.86       0.86  27112.43   \n",
      "LassoLars                                    0.86       0.86  27112.50   \n",
      "Ridge                                        0.86       0.86  27114.15   \n",
      "BayesianRidge                                0.86       0.86  27121.28   \n",
      "RidgeCV                                      0.86       0.86  27131.14   \n",
      "LarsCV                                       0.86       0.86  27139.96   \n",
      "LassoLarsCV                                  0.86       0.86  27139.96   \n",
      "LassoCV                                      0.86       0.86  27163.82   \n",
      "HuberRegressor                               0.85       0.86  27938.13   \n",
      "KNeighborsRegressor                          0.85       0.86  27997.07   \n",
      "PassiveAggressiveRegressor                   0.85       0.85  28173.76   \n",
      "RANSACRegressor                              0.84       0.84  29443.86   \n",
      "OrthogonalMatchingPursuitCV                  0.82       0.83  30421.72   \n",
      "ElasticNet                                   0.82       0.83  30656.48   \n",
      "AdaBoostRegressor                            0.82       0.82  31108.17   \n",
      "GammaRegressor                               0.80       0.81  32473.99   \n",
      "ExtraTreeRegressor                           0.78       0.79  33817.52   \n",
      "TweedieRegressor                             0.78       0.79  34071.60   \n",
      "DecisionTreeRegressor                        0.77       0.78  34981.07   \n",
      "OrthogonalMatchingPursuit                    0.59       0.61  46304.06   \n",
      "ElasticNetCV                                 0.06       0.09  70511.23   \n",
      "DummyRegressor                              -0.03      -0.00  73773.33   \n",
      "NuSVR                                       -0.04      -0.01  74171.97   \n",
      "SVR                                         -0.09      -0.06  75929.66   \n",
      "GaussianProcessRegressor                    -0.37      -0.33  85061.82   \n",
      "KernelRidge                                 -5.12      -4.94 179793.73   \n",
      "MLPRegressor                                -5.81      -5.62 189755.01   \n",
      "LinearSVR                                   -5.90      -5.70 190976.61   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "GradientBoostingRegressor            0.34  \n",
      "HistGradientBoostingRegressor        0.17  \n",
      "LGBMRegressor                        0.08  \n",
      "PoissonRegressor                     1.07  \n",
      "XGBRegressor                         0.08  \n",
      "ExtraTreesRegressor                  0.47  \n",
      "RandomForestRegressor                1.05  \n",
      "BaggingRegressor                     0.11  \n",
      "SGDRegressor                         0.01  \n",
      "TransformedTargetRegressor           0.01  \n",
      "LinearRegression                     0.01  \n",
      "Lars                                 0.01  \n",
      "LassoLarsIC                          0.02  \n",
      "Lasso                                0.01  \n",
      "LassoLars                            0.01  \n",
      "Ridge                                0.01  \n",
      "BayesianRidge                        0.01  \n",
      "RidgeCV                              0.01  \n",
      "LarsCV                               0.02  \n",
      "LassoLarsCV                          0.02  \n",
      "LassoCV                              0.06  \n",
      "HuberRegressor                       0.05  \n",
      "KNeighborsRegressor                  0.03  \n",
      "PassiveAggressiveRegressor           0.04  \n",
      "RANSACRegressor                      0.07  \n",
      "OrthogonalMatchingPursuitCV          0.02  \n",
      "ElasticNet                           0.01  \n",
      "AdaBoostRegressor                    0.14  \n",
      "GammaRegressor                       0.33  \n",
      "ExtraTreeRegressor                   0.01  \n",
      "TweedieRegressor                     0.65  \n",
      "DecisionTreeRegressor                0.02  \n",
      "OrthogonalMatchingPursuit            0.01  \n",
      "ElasticNetCV                         0.06  \n",
      "DummyRegressor                       0.00  \n",
      "NuSVR                                0.12  \n",
      "SVR                                  0.18  \n",
      "GaussianProcessRegressor             0.20  \n",
      "KernelRidge                          0.11  \n",
      "MLPRegressor                         0.96  \n",
      "LinearSVR                            0.01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "features = ['GrLivArea', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "            'Age', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "            'LowQualFinSF', 'BedroomAbvGr']\n",
    "X = housing[features]  # Features\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "reg = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b825dfe-ff16-405c-8c25-f172ef297647",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3edb7dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   41.68\n",
       "1   25.16\n",
       "2   10.89\n",
       "3    2.45\n",
       "4   23.59\n",
       "Name: VIF, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a DataFrame with your features (X)\n",
    "X = housing[['OverallQual', 'TotalSF', 'GarageCars', 'Fireplaces', 'YearRemodAdd']]\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Features\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"VIF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16156f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   23.99\n",
       "1   23.99\n",
       "2   10.82\n",
       "3    2.31\n",
       "Name: VIF, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#High multicollinearity above. If YearRemodAdd is removed, it's improved\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a DataFrame with your features (X)\n",
    "X = housing[['OverallQual', 'TotalSF', 'GarageCars', 'Fireplaces']]\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Features\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"VIF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b4b5e-25e6-4123-9374-29b543784b26",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe1fecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9099304382867012\n",
      "RMSE: 22140.07462339106\n"
     ]
    }
   ],
   "source": [
    "X = housing.drop(['SalePrice','DateSold'],axis=1) # Features\n",
    "y = housing['SalePrice']  # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create transformers\n",
    "#numeric_transformer = Pipeline(steps=[\n",
    "#    ('imputer', SimpleImputer(strategy='median')),\n",
    "#    ('scaler', StandardScaler())])\n",
    "\n",
    "#categorical_transformer = Pipeline(steps=[\n",
    "#    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#        ('num', numeric_transformer, numerical_features),\n",
    "#        ('cat', categorical_transformer, cat_nom_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "#pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                           ('classifier', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# Preprocessing of training data and train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n",
    "print(f'RMSE: {mean_squared_error(y_test, y_pred, squared=False)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9856c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for fold 1: 0.8919\n",
      "R^2 Score for fold 2: 0.9188\n",
      "R^2 Score for fold 3: 0.8961\n",
      "R^2 Score for fold 4: 0.9074\n",
      "R^2 Score for fold 5: 0.9134\n",
      "\n",
      "Average R^2 Score across the 5 folds: 0.9055\n"
     ]
    }
   ],
   "source": [
    "# Compute the R^2 scores\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "# Print R^2 score for each fold\n",
    "for i, score in enumerate(scores, 1):\n",
    "    print(f\"R^2 Score for fold {i}: {score:.4f}\")\n",
    "\n",
    "# Print average R^2 score\n",
    "print(f\"\\nAverage R^2 Score across the 5 folds: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f6671bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street: 3.10290206693358e-07\n",
      "Condition2: 3.183780363041528e-06\n",
      "PoolArea: 6.877201161457286e-06\n",
      "PoolQC: 7.312975638993055e-06\n",
      "3SsnPorch: 2.9252217528054584e-05\n",
      "MiscFeature: 3.004777856017271e-05\n",
      "Heating: 3.786785257546531e-05\n",
      "MiscVal: 5.4764544458474466e-05\n",
      "RoofMatl: 7.580615451247284e-05\n",
      "Electrical: 0.00012042599783593619\n",
      "Alley: 0.0001916344974664655\n",
      "LandSlope: 0.00019220448173472805\n",
      "LowQualFinSF: 0.00020669352796820597\n",
      "GarageQual: 0.00026259671963814804\n",
      "DistanceCategory: 0.0002637215668529297\n",
      "BsmtFinSF2: 0.0002831394745820714\n",
      "Fence: 0.00028326963946327134\n",
      "BsmtCond: 0.00029873798370696667\n",
      "BsmtFinType2: 0.00031332168224912544\n",
      "SaleType: 0.0003301664156474549\n",
      "PavedDrive: 0.00035982610321008587\n",
      "HouseStyle: 0.00037233286486706074\n",
      "ExterCond: 0.00039749402664791833\n",
      "BldgType: 0.00044607638165485746\n",
      "Foundation: 0.00047834210153657877\n",
      "LotConfig: 0.0005222372571232471\n",
      "LandContour: 0.0005334447424462982\n",
      "GarageCond: 0.000545689845686773\n",
      "Condition1: 0.0005458371117463052\n",
      "Functional: 0.0005930975248358489\n",
      "KitchenAbvGr: 0.000597268034078584\n",
      "RoofStyle: 0.0006559231374723814\n",
      "GarageType: 0.0006684227202406161\n",
      "MA_Zip1: 0.0007230757698894713\n",
      "LotShape: 0.0007337791939552051\n",
      "GarageFinish: 0.0007911415117045242\n",
      "EnclosedPorch: 0.0008071541955495318\n",
      "FireplaceQu: 0.0009110024293553079\n",
      "MasVnrType: 0.000988167246495522\n",
      "BsmtFinType1: 0.0010665966788940557\n",
      "BedroomAbvGr: 0.0010866648095322212\n",
      "YearsSinceRemod: 0.001142275048273883\n",
      "HeatingQC: 0.0011548350168385552\n",
      "YrSold: 0.0013194500111382186\n",
      "MSZoning: 0.0013715128800681332\n",
      "BsmtExposure: 0.0013724279801802166\n",
      "CentralAir: 0.0013867926248326658\n",
      "SaleCondition: 0.0013869920101315582\n",
      "Exterior2nd: 0.0014214424207225006\n",
      "BsmtBath: 0.0015705166176321543\n",
      "Exterior1st: 0.001762576170920729\n",
      "MSSubClass: 0.0019113237389430712\n",
      "MiscRmsAbvGrd: 0.0020484293370826765\n",
      "MoSold: 0.002117381789640624\n",
      "ExterQual: 0.0022385747860923133\n",
      "2ndFlrSF: 0.0024145457342147876\n",
      "WoodDeckSF: 0.0024608214069114847\n",
      "Bath: 0.0027669995564025968\n",
      "GarageCars: 0.0028534714833645374\n",
      "OpenPorchSF: 0.0032030880367306786\n",
      "GarageYrBlt: 0.0034172058210844747\n",
      "ScreenPorch: 0.0036831484914099464\n",
      "TotalBsmtSF: 0.0037797935627720174\n",
      "OverallCond: 0.004196760568454777\n",
      "Fireplaces: 0.0043058084431022966\n",
      "DistanceToISU: 0.004364712213523165\n",
      "1stFlrSF: 0.004471715309527092\n",
      "LotFrontage: 0.004754313219884942\n",
      "BsmtQual: 0.0068061095135412255\n",
      "BsmtFinSF1: 0.007145145093666298\n",
      "MasVnrArea: 0.007254492590946635\n",
      "Neighborhood: 0.007357952492090961\n",
      "BsmtUnfSF: 0.007759273077493598\n",
      "KitchenQual: 0.008120342515609905\n",
      "LotArea: 0.008727540651307148\n",
      "GarageArea: 0.008732088921637075\n",
      "GrLivArea: 0.010629870604429366\n",
      "YearRemodAdd: 0.012562619185014851\n",
      "Age: 0.02398389531631249\n",
      "TotalSF: 0.39920613152166534\n",
      "OverallQual: 0.4060227157673325\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to one-hot encoding\n",
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "# Handle missing data by filling with the mean value of each column\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "\n",
    "# Now, try training the model again\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# To sort features by importance\n",
    "sorted_idx = importances.argsort()\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{X_train.columns[idx]}: {importances[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2a7593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDwAAAK7CAYAAAAeD5+5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAACHTUlEQVR4nOzde3zP9f//8ft759kJc9issTHMclqhRDmESXxQTjmODgohFD4+QpIKRSRijsmhQkjOh5xyqIgMOVNEw5Y5bnv+/vDb++ttw8bYvLpdL5fXJe/n6/l6PR+v90nvu+fr9bIZY4wAAAAAAAAsxCm7CwAAAAAAAMhqBB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAJANbDZbhpY1a9bc81qmTZumFi1aqGTJknJyclJISMhN+54/f17du3dXoUKF5OHhofLly2vWrFkZGmfgwIGy2WxycnLSwYMH06xPTEyUr6+vbDaboqOj7/Bobm337t0aOHCgDh8+nKH+U6ZMkc1m07Zt2+5JPffDl19+qZEjR96Xse70+U1v6dWrV46oMSeaPXu2Hn74YXl6espms2n79u3ZXdJN3fgau7i4KDAwUC1atNDvv/+ebXWlfh9l59jpLWPGjMmWmm7lwoULGjhwYLp/H+XU1xcAUrlkdwEA8G+0adMmh8eDBw/W6tWrtWrVKof2iIiIe17L9OnTdfLkSVWqVEkpKSm6evXqTfs+99xz2rp1q95//32VKFFCX375pV544QWlpKSoZcuWGRrP29tbkydP1uDBgx3av/rqK129elWurq53dTy3snv3bg0aNEjVq1e/ZbBjJV9++aV27dql7t273/Ox7vT5nTx5ssLDwx3aChUqlMXVXfOgvwdOnz6tNm3aqG7duho7dqzc3d1VokSJ7C7rtlJf40uXLmnDhg0aMmSIVq9erT179ihPnjzZXV62WLJkifz8/BzaQkNDs6mam7tw4YIGDRokSapevXq6fXh9AeRUBB4AkA0ef/xxh8f58+eXk5NTmvb7YenSpXJyujbhr379+tq1a1e6/RYvXqzly5fbQw5JqlGjho4cOaI333xTzZs3l7Oz823Ha968uaZOnapBgwbZx5WkmJgYNW7cWAsWLMiCo8KFCxeUK1eu7C4jQ0qXLq0KFSpkdxl35erVq/Z/4b6X9u3bp6tXr6p169aqVq3aLfvmpPfA9a9x9erVlZycrAEDBmj+/Plq3759NleXPR599FHly5cvy/ebHa97Tnp9L168KE9Pz/s65t3ISZ9TwIo4pQUAcqgzZ86oU6dOCgoKkpubm4oWLap+/frp8uXLDv1sNpu6dOmi8ePHq0SJEnJ3d1dERESGTzW5PnS4lXnz5snb21tNmzZ1aG/fvr3+/PNPbd68OUP76dChg44dO6bly5fb2/bt26f169erQ4cO6W5z9OhRtW7dWgUKFJC7u7tKlSqlESNGKCUlxaHfZ599pnLlysnb21s+Pj4KDw/Xf//7X0nXpl6n1l6jRg37FOwpU6ZkqO5U0dHR8vb21p49exQVFSUvLy8FBgbq/ffflyT9+OOPqlq1qry8vFSiRAlNnTrVYfvUKeDLly9X+/btlTdvXnl5ealBgwbpnuozadIklStXTh4eHsqbN68aN26s2NjYdGvauXOn6tSpIx8fHz399NOqXr26vvvuOx05csRh2nmqQYMG6bHHHlPevHnl6+urRx55RDExMTLGOOw/JCRE9evX15IlS/TII4/I09NT4eHhmjRpksNxZcXzm57Zs2ercuXK8vLykre3t6KiovTLL7849Nm2bZtatGihkJAQeXp6KiQkRC+88IKOHDmS4RpDQkLSPZ2qevXqDv+yvWbNGtlsNk2fPl09e/ZUUFCQ3N3dtX//fknSihUr9PTTT8vX11e5cuVSlSpVtHLlSod9nj59Wq+88oqCg4Pl7u6u/Pnzq0qVKlqxYsVNn4fo6GhVrVpV0rXg0Gaz2eu62XtAyvx3yeTJk1WyZEl5enqqQoUK+vHHH2WM0bBhwxQaGipvb2/VrFnTfrx3IvXH8V9//WVvu3Tpknr27Kny5cvLz89PefPmVeXKlfXtt9+m2T611unTp6tUqVLKlSuXypUrp0WLFqXp+91336l8+fJyd3dXaGiohg8fnm5Nly5dUt++fRUaGio3NzcFBQWpc+fOOnfunEO/1M/DokWLFBkZKU9PT5UqVco+9pQpU1SqVCl5eXmpUqVKd3xK3N189iXpypUrevfddxUeHm5/j7Vv316nT5922MeqVatUvXp1+fv7y9PTU4ULF9bzzz+vCxcu6PDhw8qfP7+ka98XqZ+Z2512mN7rK137nP7nP/9R3rx55eHhocjISM2ZMyfN9uvXr1flypXl4eGhoKAg9e/fXxMnTpTNZnM4HS31tZg7d64iIyPl4eFhn41y8uRJdezYUQ899JDc3NwUGhqqQYMGKSkpyWGsW/29IV0LJHr16qXQ0FD7a1GhQgXNnDnTYT8LFixQ5cqVlStXLvn4+Kh27dppZnOmns70888/q0mTJsqTJ4+KFSt2y+cSwF0yAIBs165dO+Pl5WV/fPHiRVO2bFnj5eVlhg8fbpYtW2b69+9vXFxcTL169Ry2lWSCg4NNRESEmTlzplmwYIGpW7eukWS++uqrTNXx7LPPmiJFiqS77vHHHzcVK1ZM075r1y4jyYwfP/6W+x4wYICRZE6fPm2efPJJ06xZM/u63r17m5CQEJOSkmK8vLxMu3bt7OtOnTplgoKCTP78+c24cePMkiVLTJcuXYwk89prr9n7zZw500gyr7/+ulm2bJlZsWKFGTdunOnatat9P++9956RZD799FOzadMms2nTJnPq1Kmb1jx58mQjyWzdutXe1q5dO+Pm5mZKlSplRo0aZZYvX27at29vJJm+ffuaEiVKmJiYGLN06VJTv359I8ls27YtzT6Dg4NNhw4dzPfff28+//xzU6BAARMcHGzOnj1r75ta7wsvvGC+++47M23aNFO0aFHj5+dn9u3b51CTq6urCQkJMUOHDjUrV640S5cuNb/99pupUqWKCQgIsB/vpk2b7NtFR0ebmJgYs3z5crN8+XIzePBg4+npaQYNGuTwPBQpUsQ89NBDJiIiwkybNs0sXbrUNG3a1Egya9euvevn98cffzRXr151WFINGTLE2Gw206FDB7No0SIzd+5cU7lyZePl5WV+++03e7+vvvrKvP3222bevHlm7dq1ZtasWaZatWomf/785vTp0xmqsUiRIg7vvVTVqlUz1apVsz9evXq1kWSCgoJMkyZNzIIFC8yiRYtMXFycmT59urHZbKZRo0Zm7ty5ZuHChaZ+/frG2dnZrFixwr6PqKgokz9/fvP555+bNWvWmPnz55u3337bzJo166bP1/79+82nn35qJJn33nvPbNq0yf4c3Ow9kNnvkiJFipgnnnjCzJ0718ybN8+UKFHC5M2b17zxxhumYcOGZtGiRWbGjBmmYMGCpmzZsiYlJeWm9V7/Gl//GTLGmDFjxhhJ5ptvvrG3nTt3zkRHR5vp06ebVatWmSVLlphevXoZJycnM3Xq1DS1hoSEmEqVKpk5c+aYxYsXm+rVqxsXFxdz4MABe78VK1YYZ2dnU7VqVTN37lzz1VdfmYoVK5rChQub6/83OCUlxURFRRkXFxfTv39/s2zZMjN8+HDj5eVlIiMjzaVLl+x9Uz8PpUuXNjNnzjSLFy82jz32mHF1dTVvv/22qVKlisPzV7BgQXPhwgX79qnfhSdPnnR4zyclJdn73O1nPzk52dStW9d4eXmZQYMGmeXLl5uJEyeaoKAgExERYa/n0KFDxsPDw9SuXdvMnz/frFmzxsyYMcO0adPGnD171ly6dMksWbLESDIvvvii/TOzf//+TL++q1atMm5ububJJ580s2fPNkuWLDHR0dFGkpk8ebK9344dO4yHh4cpW7asmTVrllmwYIGpV6+eCQkJMZLMoUOHHF6LwMBAU7RoUTNp0iSzevVqs2XLFnPixAkTHBxsihQpYsaPH29WrFhhBg8ebNzd3U10dLR9+9v9vWGMMR07djS5cuUyH330kVm9erVZtGiRef/9983o0aPtfWbMmGEkmTp16pj58+eb2bNnm0cffdS4ubmZdevWpXntixQpYnr37m2WL19u5s+fbwDcOwQeAJAD3Bh4jBs3zkgyc+bMcej3wQcfGElm2bJl9jZJxtPT05w8edLelpSUZMLDw01YWFim6rhV4FG8eHETFRWVpv3PP/+0/wC7lesDj8mTJxt3d3cTFxdnkpKSTGBgoBk4cKAxxqQJPPr06WMkmc2bNzvs77XXXjM2m83s3bvXGGNMly5dTO7cuW9Zw1dffWUkmdWrV9+yX6qbBR43/o/81atXTf78+Y0k8/PPP9vb4+LijLOzs+nRo0eafTZu3NhhrA0bNhhJ5t133zXGGHP27Fnj6emZ5kfp0aNHjbu7u2nZsmWamiZNmpTmGG71ml4vOTnZXL161bzzzjvG39/f4YdskSJFjIeHhzly5Ii97eLFiyZv3rymY8eO9rY7fX7TW65evWqOHj1qXFxczOuvv+6w3T///GMCAgIcQrMbJSUlmfPnzxsvLy8zatSoDNWY2cDjqaeecuiXmJho8ubNaxo0aODQnpycbMqVK2cqVapkb/P29jbdu3e/af03kzr2jWHmzd4Dmf0uCQgIMOfPn7e3zZ8/30gy5cuXd3hPjBw50kgyv/766y3rvTHU+ueff8ySJUtMQECAeeqppxzCrRslJSWZq1evmhdffNFERkY6rJNkChYsaBISEuxtJ0+eNE5OTmbo0KH2tscee8wUKlTIXLx40d6WkJBg8ubN6xB4pP6o//DDDx3GmT17tpFkPv/8c3tbkSJFjKenpzl+/Li9bfv27UaSCQwMNImJiWmevwULFtjbUr8Lb1yCgoKMMVnz2U/9IX/995QxxmzdutVIMmPHjjXGGPP1118bSWb79u3mZk6fPm0kmQEDBqRZl5nXNzw83ERGRqZ5zevXr28CAwNNcnKyMcaYpk2bGi8vL3tQacy1z1BERES6gYezs7P974FUHTt2NN7e3g7fWcYYM3z4cCPJHhRm5O+N0qVLm0aNGt10fXJysilUqJApU6aM/RiMufY9VaBAAfPEE0/Y21Jf+7fffvuWYwLIOpzSAgA50KpVq+Tl5aUmTZo4tKdOI75xevzTTz+tggUL2h87OzurefPm2r9/v44fP55ldd3qrgaZueNB06ZN5ebmphkzZmjx4sU6efLkTadIr1q1ShEREapUqZJDe3R0tIwx9gu9VqpUSefOndMLL7ygb7/9Vn///XeG68ksm82mevXq2R+7uLgoLCxMgYGBioyMtLfnzZtXBQoUcDitIlWrVq0cHj/xxBMqUqSIVq9eLenahW0vXryY5nkJDg5WzZo107wHJOn555/P1HGsWrVKtWrVkp+fn5ydneXq6qq3335bcXFxOnXqlEPf8uXLq3DhwvbHHh4eKlGiRLrHllnTpk3T1q1bHRYXFxctXbpUSUlJatu2rZKSkuyLh4eHqlWr5nDXiPPnz6t3794KCwuTi4uLXFxc5O3trcTExDSnAWSVG5/vjRs36syZM2rXrp1DvSkpKapbt662bt2qxMRESdfer1OmTNG7776rH3/88ZYXC76bmjL7XVKjRg15eXnZH5cqVUqS9Mwzzzh8xlPbM/r6P/7443J1dZWPj4/q1q2rPHny6Ntvv01zzZOvvvpKVapUkbe3t1xcXOTq6qqYmJh0X8MaNWrIx8fH/rhgwYIOn7fExERt3bpVzz33nDw8POz9fHx81KBBA4d9pX6P3Ph5a9q0qby8vNI8T+XLl1dQUFCa56N69eoO12O41fO0YsUKh/f84sWLJWXNZ3/RokXKnTu3GjRo4PBeLF++vAICAuyfnfLly8vNzU2vvPKKpk6dmu5pdRlxu9d3//792rNnj/177/qa6tWrpxMnTmjv3r2SpLVr16pmzZoO1zdxcnJSs2bN0h27bNmyaS7cu2jRItWoUUOFChVyGOuZZ56xjyFl7O+NSpUq6fvvv1efPn20Zs0aXbx40WH93r179eeff6pNmzYOp4h6e3vr+eef148//qgLFy44bJPZ72oAd47AAwByoLi4OAUEBKQJEQoUKCAXFxfFxcU5tAcEBKTZR2rbjX3vlL+/f7r7OnPmjKRrP+4zysvLS82bN9ekSZMUExOjWrVqqUiRIun2jYuLU2BgYJr21Lt4pNbUpk0bTZo0SUeOHNHzzz+vAgUK6LHHHnO4VkhWyZUrl8MPKElyc3NL9zlwc3PTpUuX0rTf7DVLPZ7U/97s2G98LXLlyiVfX98MH8OWLVtUp04dSdKECRO0YcMGbd26Vf369ZOkNP9T7+/vn2Yf7u7uafrdiVKlSqlChQoOi/R/5/9XrFhRrq6uDsvs2bMdfpy0bNlSY8aM0UsvvaSlS5dqy5Yt2rp1q/Lnz58lNabnxtcmtd4mTZqkqfeDDz6QMcb+eZk9e7batWuniRMnqnLlysqbN6/atm2rkydP3nE96b0HMvtdcuN72M3N7Zbt6b2305Maaq1atUodO3ZUbGys/eLHqebOnatmzZopKChIX3zxhTZt2qStW7eqQ4cO6Y5zu/fk2bNnlZKScsvvx1RxcXFycXGxX68ilc1mc/hcpsqK56lcuXIO7/myZcvaa5Hu7rP/119/6dy5c3Jzc0vzXjx58qT9s1OsWDGtWLFCBQoUUOfOnVWsWDEVK1ZMo0aNSjP2rdzu9U39bPTq1StNPZ06dZIke01xcXEOAX6q9Nqk9J+nv/76SwsXLkwz1sMPP+wwVkb+3vjkk0/Uu3dvzZ8/XzVq1FDevHnVqFEj+213b/d6paSk6OzZs7etGcC9wV1aACAH8vf31+bNm2WMcfihcurUKSUlJaW5sn96P5JS29L7UXAnypQpo5kzZyopKcnhX2V37twp6dpV+jOjQ4cOmjhxon799VfNmDHjpv38/f114sSJNO1//vmnJDk8F+3bt1f79u2VmJioH374QQMGDFD9+vW1b9++mwYq2eVmr1lYWJik/3vdbnbsN74HMjPDRpJmzZolV1dXLVq0yCG8mT9/fqb2cy+lHuPXX399y9cvPj5eixYt0oABA9SnTx97++XLl+0BQ0Z4eHikuZCndO3HUXp307jxOU/tM3r06JvecSn1R1u+fPk0cuRIjRw5UkePHtWCBQvUp08fnTp1SkuWLMlwzbeqR8r8d8m9khpqSddmZiQnJ2vixIn6+uuv7bNPvvjiC4WGhmr27NkOtab3mmREnjx5ZLPZbvn9mMrf319JSUk6ffq0Q+hhjNHJkydVsWLFO6rhTmTFZz9fvnzy9/e/6Xvp+pkxTz75pJ588kklJydr27ZtGj16tLp3766CBQuqRYsWGar5dq9vas19+/bVc889l+4+SpYsKena8d94sVMp/e9M6ebHX7ZsWQ0ZMiTdba6/7fXt/t7w8vLSoEGDNGjQIP3111/22R4NGjTQnj17bvt6OTk5pbk1b2a/rwHcOWZ4AEAO9PTTT+v8+fNpfnxOmzbNvv56K1eudPgfxOTkZM2ePVvFihXTQw89lCU1NW7cWOfPn9c333zj0D516lQVKlRIjz32WKb2V7lyZXXo0EGNGzdW48aNb9rv6aef1u7du/Xzzz87tE+bNk02m001atRIs42Xl5eeeeYZ9evXT1euXNFvv/0m6dq//kppZy9khxtDno0bN+rIkSP2u25UrlxZnp6e+uKLLxz6HT9+XKtWrUrzHriZm83CSL2F6vW3Er548aKmT5+eySNxHCt1P1khKipKLi4uOnDgQJoZINfPBLHZbDLG2MdPNXHiRCUnJ2e4xpCQEP36668Obfv27bNPtb+dKlWqKHfu3Nq9e/dN6039F//rFS5cWF26dFHt2rXTvM/vVma/S+6XDz/8UHny5NHbb79tv9uSzWaTm5ubw4/BkydPpnuXloxIvUvK3LlzHWZY/PPPP1q4cKFD39Tn4cbP2zfffKPExMT7+jxlxWe/fv36iouLU3Jycrrvw9Rw4XrOzs567LHH9Omnn0qS/b14J5/rG1/fkiVLqnjx4tqxY8dNPxupIUy1atW0atUqhxlcKSkp+uqrrzI8fuot1osVK5buWNcHHqlu9vfG9QoWLKjo6Gi98MIL2rt3ry5cuKCSJUsqKChIX375pcMdrhITE/XNN9/Y79wCIHswwwMAcqC2bdvq008/Vbt27XT48GGVKVNG69ev13vvvad69eqpVq1aDv3z5cunmjVrqn///vLy8tLYsWO1Z8+eDN2advfu3dq9e7ekaz8uLly4oK+//lqSFBERoYiICEnXzuGvXbu2XnvtNSUkJCgsLEwzZ87UkiVL9MUXXzj8cM6omJiY2/Z54403NG3aND377LN65513VKRIEX333XcaO3asXnvtNfu52y+//LI8PT1VpUoVBQYG6uTJkxo6dKj8/Pzs/zqbOgvl888/l4+Pjzw8PBQaGppls2AyY9u2bXrppZfUtGlTHTt2TP369VNQUJB9enfu3LnVv39//fe//1Xbtm31wgsvKC4uToMGDZKHh4cGDBiQoXHKlCmjuXPn6rPPPtOjjz4qJycnVahQQc8++6w++ugjtWzZUq+88ori4uI0fPjwNKFBZmT18xsSEqJ33nlH/fr108GDB+3XBvjrr7+0ZcsW+7+8+vr66qmnntKwYcOUL18+hYSEaO3atYqJiVHu3LkzXGObNm3UunVrderUSc8//7yOHDmiDz/8MM1pDjfj7e2t0aNHq127djpz5oyaNGmiAgUK6PTp09qxY4dOnz6tzz77TPHx8apRo4Zatmyp8PBw+fj4aOvWrVqyZMlN//X7TmX2u+R+yZMnj/r27au33npLX375pVq3bm2/vWinTp3UpEkTHTt2TIMHD1ZgYKD99IHMGjx4sOrWravatWurZ8+eSk5O1gcffCAvLy+H2T+1a9dWVFSUevfurYSEBFWpUkW//vqrBgwYoMjISLVp0yarDv22suKz36JFC82YMUP16tVTt27dVKlSJbm6uur48eNavXq1GjZsqMaNG2vcuHFatWqVnn32WRUuXFiXLl2y32469b3h4+OjIkWK6Ntvv9XTTz+tvHnz2j9nN5Pe6zt+/Hg988wzioqKUnR0tIKCgnTmzBnFxsbq559/tgca/fr108KFC/X000+rX79+8vT01Lhx4+zXv8nIrdTfeecdLV++XE888YS6du2qkiVL6tKlSzp8+LAWL16scePG6aGHHsrQ3xuPPfaY6tevr7JlyypPnjyKjY3V9OnTHYKMDz/8UK1atVL9+vXVsWNHXb58WcOGDdO5c+fstywHkE2y8YKpAID/78a7tBhz7Q4fr776qgkMDDQuLi6mSJEipm/fvg63RzTm2t0KOnfubMaOHWuKFStmXF1dTXh4uJkxY0aGxr7ZHQOUzlX5//nnH9O1a1cTEBBg3NzcTNmyZc3MmTMzNc71V95Pz413aTHGmCNHjpiWLVsaf39/4+rqakqWLGmGDRvmcEX8qVOnmho1apiCBQsaNzc3U6hQIdOsWbM0d5EYOXKkCQ0NNc7Ozmluh3ijm92l5cbXyphrd/J4+OGH07QXKVLEPPvss2n2uWzZMtOmTRuTO3du+x0Zfv/99zTbT5w40ZQtW9a4ubkZPz8/07BhQ4fbsd6qJmOMOXPmjGnSpInJnTu3sdlsDnemmDRpkilZsqRxd3c3RYsWNUOHDjUxMTHp3gnh+mO4/pivv3uJMXf//KZn/vz5pkaNGsbX19e4u7ubIkWKmCZNmjjc5vX48ePm+eefN3ny5DE+Pj6mbt26ZteuXeneeeVmNaakpJgPP/zQFC1a1Hh4eJgKFSqYVatW3fQuLTe77fPatWvNs88+a/LmzWtcXV1NUFCQefbZZ+39L126ZF599VVTtmxZ4+vrazw9PU3JkiXNgAEDHO7wkZ5b3aXlZu+BzH6XXO/QoUNGkhk2bFiG6rjRrV7jixcvmsKFC5vixYvbb8n6/vvvm5CQEOPu7m5KlSplJkyYYP/uuF2txqR/p50FCxbYP0OFCxc277//frr7vHjxoundu7cpUqSIcXV1NYGBgea1115zuFV06hjpfR4y+vxl9Lvwbj/7V69eNcOHDzflypUzHh4extvb24SHh5uOHTvav2s2bdpkGjdubIoUKWLc3d2Nv7+/qVatmsNdZYy5dnvfyMhI4+7ubiTZn+PMvr47duwwzZo1MwUKFDCurq4mICDA1KxZ04wbN85h23Xr1pnHHnvMuLu7m4CAAPPmm2/a7yx07tw5e7+bvRbGXLu7TNeuXU1oaKhxdXU1efPmNY8++qjp16+f/U5EGfl7o0+fPqZChQomT5489u/KN954w/z9998O482fP9889thjxsPDw3h5eZmnn37abNiwwaFPRl97AFnHZsx1c68AAA8cm82mzp07a8yYMdldCjJgypQpat++vbZu3Wo/JQMAcGt16tTR4cOHtW/fvuwuBcADhFNaAAAAAOQYPXr0UGRkpIKDg3XmzBnNmDFDy5cvz9BpkABwPQIPAAAAADlGcnKy3n77bZ08eVI2m00RERGaPn26Wrdund2lAXjAcEoLAAAAAACwHG5LCwAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwuWoo7lpKSoj///FM+Pj6y2WzZXQ4AAAAAwOKMMfrnn39UqFAhOTndeg4HgQfu2J9//qng4ODsLgMAAAAA8C9z7NgxPfTQQ7fsQ+CBO+bj4yPp2hvN19c3m6sBAAAAAFhdQkKCgoOD7b9Hb4XAA3cs9TQWX19fAg8AAAAAwH2TkcsqcNFSAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMtxye4C8OD7aEecPLyvZHcZAAAAAIA70CcyX3aXcE8wwwMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAKPbFS9enV1797d/jgkJEQjR47MMfUAAAAAAPCgsnTgcezYMb344osqVKiQ3NzcVKRIEXXr1k1xcXHZXVqGbdy4UfXq1VOePHnk4eGhMmXKaMSIEUpOTs7u0gAAAAAAyLEsG3gcPHhQFSpU0L59+zRz5kzt379f48aN08qVK1W5cmWdOXPmno199erVLNnPvHnzVK1aNT300ENavXq19uzZo27dumnIkCFq0aKFjDFZMg4AAAAAAFZj2cCjc+fOcnNz07Jly1StWjUVLlxYzzzzjFasWKE//vhD/fr1U9++ffX444+n2bZs2bIaMGCA/fHkyZNVqlQpeXh4KDw8XGPHjrWvO3z4sGw2m+bMmaPq1avLw8NDX3zxheLi4vTCCy/ooYceUq5cuVSmTBnNnDkzw/UnJibq5Zdf1n/+8x99/vnnKl++vEJCQvTSSy9p6tSp+vrrrzVnzhxJ0po1a2Sz2XTu3Dn79tu3b5fNZtPhw4cl6a7rAQAAAADgQWLJwOPMmTNaunSpOnXqJE9PT4d1AQEBatWqlWbPnq2WLVtq8+bNOnDggH39b7/9pp07d6pVq1aSpAkTJqhfv34aMmSIYmNj9d5776l///6aOnWqw3579+6trl27KjY2VlFRUbp06ZIeffRRLVq0SLt27dIrr7yiNm3aaPPmzRk6hmXLlikuLk69evVKs65BgwYqUaJEpgKLu61Hki5fvqyEhASHBQAAAACAnMgluwu4F37//XcZY1SqVKl015cqVUpnz55VwYIFVbZsWX355Zfq37+/JGnGjBmqWLGiSpQoIUkaPHiwRowYoeeee06SFBoaqt27d2v8+PFq166dfZ/du3e390l1fVjx+uuva8mSJfrqq6/02GOP3fYY9u3bZ681PeHh4fY+GREUFHRX9UjS0KFDNWjQoAyPCQAAAABAdrHkDI/bSb32hc1mU6tWrTRjxgx7+8yZM+2zO06fPm2/8Km3t7d9effddx1mhUhShQoVHB4nJydryJAhKlu2rPz9/eXt7a1ly5bp6NGjd1Rreu1ubm4Z3k9W1NO3b1/Fx8fbl2PHjmV4WwAAAAAA7idLzvAICwuTzWbT7t271ahRozTr9+zZozx58ihfvnxq2bKl+vTpo59//lkXL17UsWPH1KJFC0lSSkqKpGuntdw4C8LZ2dnhsZeXl8PjESNG6OOPP9bIkSNVpkwZeXl5qXv37rpy5UqGjqF48eKSpNjYWD3xxBPpHkP58uUlSU5O13Kr68ORGy+cerf1SJK7u7vc3d0z3B8AAAAAgOxiycDD399ftWvX1tixY/XGG284XMfj5MmTmjFjhtq2bSubzaaHHnpITz31lGbMmKGLFy+qVq1aKliwoCSpYMGCCgoK0sGDB+2zPjJq3bp1atiwoVq3bi3pWnjy+++/3/QUlRtFRUUpb968GjFiRJrAY8GCBfr99981cuRISVL+/PklSSdOnFCePHkkXbtoaVbWAwAAAADAg8Syp7SMGTNGly9fVlRUlH744QcdO3ZMS5YsUe3atRUUFKQhQ4bY+7Zq1UqzZs3SV199ZQ8EUg0cOFBDhw7VqFGjtG/fPu3cuVOTJ0/WRx99dMvxw8LCtHz5cm3cuFGxsbHq2LGjTp48meH6vby8NH78eH377bd65ZVX9Ouvv+rw4cOKiYlRdHS0XnrpJdWrV88+VnBwsAYOHKh9+/bpu+++04gRI7K0HgAAAAAAHiSWDTyKFy+ubdu2qVixYmrevLmKFSumV155RTVq1NCmTZuUN29ee9+mTZsqLi5OFy5cSHMKzEsvvaSJEydqypQpKlOmjKpVq6YpU6YoNDT0luP3799fjzzyiKKiolS9enUFBASke3rNrTRp0kSrV6/W0aNH9eSTTyo0NFQvvfSSevfurQkTJtj7ubq6aubMmdqzZ4/KlSunDz74QO+++26W1wMAAAAAwIPCZm52VUzkOJcuXVLDhg117NgxrV271n4qS3ZJSEiQn5+fBvxwUB7ePtlaCwAAAADgzvSJzJfdJWRY6u/Q+Ph4+fr63rKvZWd4WJGHh4e+/fZbtW3bVj/88EN2lwMAAAAAQI5lyYuWWpmHh4f69OmT3WUAAAAAAJCjMcMDAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAy+G2tLhrPcr5y9fXN7vLAAAAAADAjhkeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWI5LdheAB99HO+Lk4X0lu8sAAAAAgH+tPpH5sruEHIcZHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwsJCQkRCNHjszuMgAAAAAAyHYEHveAzWa75RIdHX3b7efPn3/Xdfzyyy+qX7++ChQoIA8PD4WEhKh58+b6+++/JUmHDx9Ot77WrVvf9dgAAAAAAGQnl+wuwIpOnDhh//Ps2bP19ttva+/evfY2T0/Pe17DqVOnVKtWLTVo0EBLly5V7ty5dejQIS1YsEAXLlxw6LtixQo9/PDD97U+AAAAAADuJWZ43AMBAQH2xc/PTzabzaHtyy+/VLFixeTm5qaSJUtq+vTp9m1DQkIkSY0bN5bNZrM/PnDggBo2bKiCBQvK29tbFStW1IoVK25aw8aNG5WQkKCJEycqMjJSoaGhqlmzpkaOHKnChQs79PX3909TMwAAAAAADzICj/ts3rx56tatm3r27Kldu3apY8eOat++vVavXi1J2rp1qyRp8uTJOnHihP3x+fPnVa9ePa1YsUK//PKLoqKi1KBBAx09ejTdcQICApSUlKR58+bJGJMltV++fFkJCQkOCwAAAAAAORGBx302fPhwRUdHq1OnTipRooR69Oih5557TsOHD5ck5c+fX5KUO3duBQQE2B+XK1dOHTt2VJkyZVS8eHG9++67Klq0qBYsWJDuOI8//rj++9//qmXLlsqXL5+eeeYZDRs2TH/99Veavk888YS8vb3tyy+//JLuPocOHSo/Pz/7EhwcnBVPCQAAAAAAWY7A4z6LjY1VlSpVHNqqVKmi2NjYW26XmJiot956SxEREcqdO7e8vb21Z8+em87wkKQhQ4bo5MmTGjdunCIiIjRu3DiFh4dr586dDv1mz56t7du325eIiIh099e3b1/Fx8fbl2PHjmXwqAEAAAAAuL+4aGk2sNlsDo+NMWnabvTmm29q6dKlGj58uMLCwuTp6akmTZroypUrt9zO399fTZs2VdOmTTV06FBFRkZq+PDhmjp1qr1PcHCwwsLCblu3u7u73N3db9sPAAAAAIDsxgyP+6xUqVJav369Q9vGjRtVqlQp+2NXV1clJyc79Fm3bp2io6PVuHFjlSlTRgEBATp8+HCmxnZzc1OxYsWUmJh4x/UDAAAAAPAgYIbHffbmm2+qWbNmeuSRR/T0009r4cKFmjt3rsMdV0JCQrRy5UpVqVJF7u7uypMnj8LCwjR37lw1aNBANptN/fv3V0pKyk3HWbRokWbNmqUWLVqoRIkSMsZo4cKFWrx4sSZPnnw/DhUAAAAAgGzDDI/7rFGjRho1apSGDRumhx9+WOPHj9fkyZNVvXp1e58RI0Zo+fLlCg4OVmRkpCTp448/Vp48efTEE0+oQYMGioqK0iOPPHLTcSIiIpQrVy717NlT5cuX1+OPP645c+Zo4sSJatOmzb0+TAAAAAAAspXNZNU9S/Gvk5CQID8/Pw344aA8vH2yuxwAAAAA+NfqE5kvu0u4L1J/h8bHx8vX1/eWfZnhAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACzHJbsLwIOvRzl/+fr6ZncZAAAAAADYMcMDAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5bhkdwF48H20I04e3leyu4ws0ScyX3aXAAAAAADIAszwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgccDbOPGjXJ2dlbdunWzuxQAAAAAAHIUAo8H2KRJk/T6669r/fr1Onr0aHaXAwAAAABAjkHg8YBKTEzUnDlz9Nprr6l+/fqaMmWKw/oFCxaoePHi8vT0VI0aNTR16lTZbDadO3fO3mfjxo166qmn5OnpqeDgYHXt2lWJiYn390AAAAAAALgHCDweULNnz1bJkiVVsmRJtW7dWpMnT5YxRpJ0+PBhNWnSRI0aNdL27dvVsWNH9evXz2H7nTt3KioqSs8995x+/fVXzZ49W+vXr1eXLl1uOubly5eVkJDgsAAAAAAAkBMReDygYmJi1Lp1a0lS3bp1df78ea1cuVKSNG7cOJUsWVLDhg1TyZIl1aJFC0VHRztsP2zYMLVs2VLdu3dX8eLF9cQTT+iTTz7RtGnTdOnSpXTHHDp0qPz8/OxLcHDwPT1GAAAAAADuFIHHA2jv3r3asmWLWrRoIUlycXFR8+bNNWnSJPv6ihUrOmxTqVIlh8c//fSTpkyZIm9vb/sSFRWllJQUHTp0KN1x+/btq/j4ePty7Nixe3B0AAAAAADcPZfsLgCZFxMTo6SkJAUFBdnbjDFydXXV2bNnZYyRzWZz2Cb1dJdUKSkp6tixo7p27Zpm/4ULF053XHd3d7m7u2fBEQAAAAAAcG8ReDxgkpKSNG3aNI0YMUJ16tRxWPf8889rxowZCg8P1+LFix3Wbdu2zeHxI488ot9++01hYWH3vGYAAAAAAO43Ao8HzKJFi3T27Fm9+OKL8vPzc1jXpEkTxcTEaO7cufroo4/Uu3dvvfjii9q+fbv9Li6pMz969+6txx9/XJ07d9bLL78sLy8vxcbGavny5Ro9evT9PiwAAAAAALIU1/B4wMTExKhWrVppwg7p2gyP7du36+zZs/r66681d+5clS1bVp999pn9Li2pp6SULVtWa9eu1e+//64nn3xSkZGR6t+/vwIDA+/r8QAAAAAAcC/YzI0Xd4AlDRkyROPGjcvSC40mJCTIz89PA344KA9vnyzbb3bqE5kvu0sAAAAAANxE6u/Q+Ph4+fr63rIvp7RY1NixY1WxYkX5+/trw4YNGjZsmLp06ZLdZQEAAAAAcF8QeFjU77//rnfffVdnzpxR4cKF1bNnT/Xt2ze7ywIAAAAA4L4g8LCojz/+WB9//HF2lwEAAAAAQLbgoqUAAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh7u04K71KOcvX1/f7C4DAAAAAAA7ZngAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOS7ZXQAefB/tiJOH95X7MlafyHz3ZRwAAAAAwIONGR4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8crjq1aure/fud72f6OhoNWrU6L6MBQAAAABAdsuWwMMYo1q1aikqKirNurFjx8rPz09Hjx7N8nHXrFkjm81mX/z9/VWzZk1t2LAhy8e617788ks5Ozvr1Vdfze5SAAAAAADIcbIl8LDZbJo8ebI2b96s8ePH29sPHTqk3r17a9SoUSpcuHCWjnn16lX7n/fu3asTJ05ozZo1yp8/v5599lmdOnUqS8e71yZNmqS33npLs2bN0oULF7K7HAAAAAAAcpRsO6UlODhYo0aNUq9evXTo0CEZY/Tiiy/q6aefVqVKlVSvXj15e3urYMGCatOmjf7++2/7tkuWLFHVqlWVO3du+fv7q379+jpw4IB9/eHDh2Wz2TRnzhxVr15dHh4e+uKLL+zrCxQooICAAJUpU0b/+9//FB8fr82bN9vX7969+5bjV69eXa+//rq6d++uPHnyqGDBgvr888+VmJio9u3by8fHR8WKFdP333/vcMxr165VpUqV5O7ursDAQPXp00dJSUn29YmJiWrbtq28vb0VGBioESNGpPvcHT58WBs3blSfPn0UHh6ur7/+2mF9cnKyevToYX9+3nrrLRljHPpkdCwAAAAAAB5E2XoNj3bt2unpp59W+/btNWbMGO3atUujRo1StWrVVL58eW3btk1LlizRX3/9pWbNmtm3S0xMVI8ePbR161atXLlSTk5Oaty4sVJSUhz237t3b3Xt2lWxsbHpnj5z4cIFTZ48WZLk6uoqSTpx4sRtx5ekqVOnKl++fNqyZYtef/11vfbaa2ratKmeeOIJ/fzzz4qKilKbNm3ssy/++OMP1atXTxUrVtSOHTv02WefKSYmRu+++659n2+++aZWr16tefPmadmyZVqzZo1++umnNHVPmjRJzz77rPz8/NS6dWvFxMQ4rB8xYoQmTZqkmJgYrV+/XmfOnNG8efMc+mR0rOtdvnxZCQkJDgsAAAAAADmRzdz4T//32alTp1S6dGnFxcXp66+/1i+//KLNmzdr6dKl9j7Hjx9XcHCw9u7dqxIlSqTZx+nTp1WgQAHt3LlTpUuX1uHDhxUaGqqRI0eqW7du9n5r1qxRjRo15OXlJela4GGM0aOPPqpNmzbJ1dVVb7/99m3Hr169upKTk7Vu3TpJ12ZU+Pn56bnnntO0adMkSSdPnlRgYKA2bdqkxx9/XP369dM333yj2NhY2Ww2SdeuV9K7d2/Fx8frwoUL8vf317Rp09S8eXNJ0pkzZ/TQQw/plVde0ciRIyVJKSkpCgkJ0ejRo9WwYUP9/fffKlSokHbv3q2wsDBJUqFChdStWzf17t1bkpSUlKTQ0FA9+uijmj9/vs6fP5+hsW40cOBADRo0KE37gB8OysPb5zavdNboE5nvvowDAAAAAMh5EhIS5Ofnp/j4ePn6+t6yb7bfpaVAgQJ65ZVXVKpUKTVu3Fg//fSTVq9eLW9vb/sSHh4uSfbTVg4cOKCWLVuqaNGi8vX1VWhoqCSludBphQoV0h1z3bp1+vnnnzVz5kwVKVJEU6ZMsc/wyMj4klS2bFn7n52dneXv768yZcrY2woWLChJ9muDxMbGqnLlyvawQ5KqVKmi8+fP6/jx4zpw4ICuXLmiypUr29fnzZtXJUuWdKh92bJlSkxM1DPPPCNJypcvn+rUqaNJkyZJkuLj43XixAmH/bi4uDg8Fxkd60Z9+/ZVfHy8fTl27Ngt+wMAAAAAkF1csrsA6doPcheXa6WkpKSoQYMG+uCDD9L0CwwMlCQ1aNBAwcHBmjBhggoVKqSUlBSVLl1aV65cceifOpPjRqGhocqdO7dKlCihS5cuqXHjxtq1a5fc3d0zNL70f6fApLLZbA5tqcFG6mk2xhiHsCO1LbVvRifaTJo0SWfOnFGuXLnsbSkpKfrll180ePDgDO3jTif1uLu7y93d/Y62BQAAAADgfsr2GR43euSRR/Tbb78pJCREYWFhDouXl5fi4uIUGxur//3vf3r66adVqlQpnT179o7Ha9OmjVJSUjR27NgMjX+nIiIitHHjRoewYePGjfLx8VFQUJDCwsLk6uqqH3/80b7+7Nmz2rdvn/1xXFycvv32W82aNUvbt293WM6fP6/vv/9efn5+CgwMdNhPUlKSw/U5MjIWAAAAAAAPshwXeHTu3FlnzpzRCy+8oC1btujgwYNatmyZOnTooOTkZOXJk0f+/v76/PPPtX//fq1atUo9evS44/GcnJzUvXt3vf/++7pw4cJtx79TnTp10rFjx/T6669rz549+vbbbzVgwAD16NFDTk5O8vb21osvvqg333xTK1eu1K5duxQdHS0np/97iaZPny5/f381bdpUpUuXti9ly5ZV/fr17Rcv7datm95//33NmzdPe/bsUadOnXTu3Dn7fjIyFgAAAAAAD7Ic9wu3UKFC2rBhg5KTkxUVFaXSpUurW7du8vPzk5OTk5ycnDRr1iz99NNPKl26tN544w0NGzbsrsbs0KGDrl69qjFjxtx2/DsVFBSkxYsXa8uWLSpXrpxeffVVvfjii/rf//5n7zNs2DA99dRT+s9//qNatWqpatWqevTRR+3rJ02apMaNG6dbx/PPP69Fixbpr7/+Us+ePdW2bVtFR0ercuXK8vHxUePGjR36324sAAAAAAAeZNl+lxY8uFKvjstdWgAAAAAA98MDdZcWAAAAAACArEbgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJbjkt0F4MHXo5y/fH19s7sMAAAAAADsmOEBAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOXcceOzfv19Lly7VxYsXJUnGmCwrCgAAAAAA4G5kOvCIi4tTrVq1VKJECdWrV08nTpyQJL300kvq2bNnlhcIAAAAAACQWS6Z3eCNN96Qi4uLjh49qlKlStnbmzdvrjfeeEMjRozI0gKR8320I04e3leyfL99IvNl+T4BAAAAAP8OmQ48li1bpqVLl+qhhx5yaC9evLiOHDmSZYUBAAAAAADcqUyf0pKYmKhcuXKlaf/777/l7u6eJUUBAAAAAADcjUwHHk899ZSmTZtmf2yz2ZSSkqJhw4apRo0aWVocAAAAAADAncj0KS3Dhg1T9erVtW3bNl25ckVvvfWWfvvtN505c0YbNmy4FzUCAAAAAABkSqZneEREROjXX39VpUqVVLt2bSUmJuq5557TL7/8omLFit2LGgEAAAAAADIl0zM8JCkgIECDBg3K6loAAAAAAACyxB0FHpcuXdKvv/6qU6dOKSUlxWHdf/7znywpDAAAAAAA4E5lOvBYsmSJ2rZtq7///jvNOpvNpuTk5CwpDAAAAAAA4E5l+hoeXbp0UdOmTXXixAmlpKQ4LIQdAAAAAAAgJ8h04HHq1Cn16NFDBQsWvBf1WNrAgQNVvnz57C4DAAAAAADLy3Tg0aRJE61Zs+YelJJznDx5Ut26dVNYWJg8PDxUsGBBVa1aVePGjdOFCxduut3hw4dls9m0ffv2dNf36tVLK1euvKOaSpYsKTc3N/3xxx93tD0AAAAAAP8mmb6Gx5gxY9S0aVOtW7dOZcqUkaurq8P6rl27Zllx2eHgwYOqUqWKcufOrffee09lypRRUlKS9u3bp0mTJqlQoULpXpj16tWrt923t7e3vL29M13T+vXrdenSJTVt2lRTpkxRv379btn/ypUrcnNzy/Q4AAAAAABYRaZneHz55ZdaunSpvvnmG40ePVoff/yxfRk5cuQ9KPH+6tSpk1xcXLRt2zY1a9ZMpUqVUpkyZfT888/ru+++U4MGDSRdu0DruHHj1LBhQ3l5eendd9+97b6vP6Vl6dKl8vDw0Llz5xz6dO3aVdWqVXNoi4mJUcuWLdWmTRtNmjRJxhiH9SEhIXr33XcVHR0tPz8/vfzyy5KkjRs36qmnnpKnp6eCg4PVtWtXJSYm2rf74osvVKFCBfn4+CggIEAtW7bUqVOnMvuUAQAAAACQ42Q68Pjf//6nd955R/Hx8Tp8+LAOHTpkXw4ePHgvarxv4uLitGzZMnXu3FleXl7p9rHZbPY/DxgwQA0bNtTOnTvVoUOHTI1Vq1Yt5c6dW9988429LTk5WXPmzFGrVq3sbf/884+++uortW7dWrVr11ZiYmK6pxQNGzZMpUuX1k8//aT+/ftr586dioqK0nPPPadff/1Vs2fP1vr169WlSxf7NleuXNHgwYO1Y8cOzZ8/X4cOHVJ0dPRNa758+bISEhIcFgAAAAAAcqJMBx5XrlxR8+bN5eSU6U1zvP3798sYo5IlSzq058uXz346Su/eve3tLVu2VIcOHVS0aFEVKVIkU2M5OzurefPm+vLLL+1tK1eu1NmzZ9W0aVN726xZs1S8eHE9/PDDcnZ2VosWLRQTE5NmfzVr1lSvXr0UFhamsLAwDRs2TC1btlT37t1VvHhxPfHEE/rkk080bdo0Xbp0SZLUoUMHPfPMMypatKgef/xxffLJJ/r+++91/vz5dGseOnSo/Pz87EtwcHCmjhkAAAAAgPsl06lFu3btNHv27HtRS45x/SwOSdqyZYu2b9+uhx9+WJcvX7a3V6hQ4a7GadWqldasWaM///xTkjRjxgzVq1dPefLksfeJiYlR69at7Y9bt26tuXPnpjkV5sZafvrpJ02ZMsUe1Hh7eysqKkopKSk6dOiQJOmXX35Rw4YNVaRIEfn4+Kh69eqSpKNHj6Zbb9++fRUfH29fjh07dlfHDwAAAADAvZLpi5YmJyfrww8/1NKlS1W2bNk0Fy396KOPsqy4+y0sLEw2m0179uxxaC9atKgkydPT06H9Zqe9ZFSlSpVUrFgxzZo1S6+99prmzZunyZMn29fv3r1bmzdv1tatWx1mliQnJ2vmzJl67bXXblpLSkqKOnbsmO5FZAsXLqzExETVqVNHderU0RdffKH8+fPr6NGjioqK0pUrV9Kt193dXe7u7nd1zAAAAAAA3A+ZDjx27typyMhISdKuXbsc1t04M+JB4+/vr9q1a2vMmDF6/fXX7zrQyIiWLVtqxowZeuihh+Tk5KRnn33Wvi4mJkZPPfWUPv30U4dtpk+frpiYGIfA40aPPPKIfvvtN4WFhaW7fufOnfr777/1/vvv209N2bZtWxYcEQAAAAAA2S/Tgcfq1avvRR05xtixY1WlShVVqFBBAwcOVNmyZeXk5KStW7dqz549evTRR2+7j71796Zpi4iISLdvq1atNGjQIA0ZMkRNmjSRh4eHpGu3uZ0+fbreeecdlS5d2mGbl156SR9++KF27NihcuXKpbvf3r176/HHH1fnzp318ssvy8vLS7GxsVq+fLlGjx6twoULy83NTaNHj9arr76qXbt2afDgwbc9NgAAAAAAHgSZDjysrlixYvrll1/03nvvqW/fvjp+/Ljc3d0VERGhXr16qVOnTrfdR4sWLdK0pV4340bFixdXxYoVtXXrVofb+i5YsEBxcXFq3LhxutuUKVNGMTEx+uSTT9Ldb9myZbV27Vr169dPTz75pIwxKlasmJo3by5Jyp8/v6ZMmaL//ve/+uSTT/TII49o+PDh+s9//nPb4wMAAAAAIKezGWNMZjfaunWrvvrqKx09ejTN9R7mzp2bZcUhZ0tISJCfn58G/HBQHt4+Wb7/PpH5snyfAAAAAIAHV+rv0Pj4ePn6+t6yb6bv0jJr1ixVqVJFu3fv1rx583T16lXt3r1bq1atkp+f3x0XDQAAAAAAkFUyHXi89957+vjjj7Vo0SK5ublp1KhRio2NVbNmzVS4cOF7USMAAAAAAECmZDrwOHDggP1OIu7u7kpMTJTNZtMbb7yhzz//PMsLBAAAAAAAyKxMBx558+bVP//8I0kKCgqy35r23LlzunDhQtZWBwAAAAAAcAcyfZeWJ598UsuXL1eZMmXUrFkzdevWTatWrdLy5cv19NNP34saAQAAAAAAMiXTgceYMWN06dIlSVLfvn3l6uqq9evX67nnnlP//v2zvEAAAAAAAIDMuqPb0gISt6UFAAAAANxf9/S2tAAAAAAAADldhk9pcXJyks1mu2Ufm82mpKSkuy4KD5Ye5fxvm6wBAAAAAHA/ZTjwmDdv3k3Xbdy4UaNHjxZnxwAAAAAAgJwgw4FHw4YN07Tt2bNHffv21cKFC9WqVSsNHjw4S4sDAAAAAAC4E3d0DY8///xTL7/8ssqWLaukpCRt375dU6dOVeHChbO6PgAAAAAAgEzLVOARHx+v3r17KywsTL/99ptWrlyphQsXqnTp0veqPgAAAAAAgEzL8CktH374oT744AMFBARo5syZ6Z7iAgAAAAAAkBPYTAavNOrk5CRPT0/VqlVLzs7ON+03d+7cLCsOOVtm7n8MAAAAAMDdyszv0AzP8Gjbtu1tb0sLAAAAAACQE2Q48JgyZco9LAMAAAAAACDr3NFdWgAAAAAAAHIyAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLuaPAY/r06apSpYoKFSqkI0eOSJJGjhypb7/9NkuLAwAAAAAAuBOZDjw+++wz9ejRQ/Xq1dO5c+eUnJwsScqdO7dGjhyZ1fUBAAAAAABkWqYDj9GjR2vChAnq16+fnJ2d7e0VKlTQzp07s7Q4AAAAAACAO5HpwOPQoUOKjIxM0+7u7q7ExMQsKQoAAAAAAOBuZDrwCA0N1fbt29O0f//994qIiMiKmgAAAAAAAO6KS2Y3ePPNN9W5c2ddunRJxhht2bJFM2fO1NChQzVx4sR7USMAAAAAAECmZDrwaN++vZKSkvTWW2/pwoULatmypYKCgjRq1Ci1aNHiXtQIAAAAAACQKZkKPJKSkjRjxgw1aNBAL7/8sv7++2+lpKSoQIEC96o+AAAAAACATMvUNTxcXFz02muv6fLly5KkfPnyEXYAAAAAAIAcJ9MXLX3sscf0yy+/3ItaAAAAAAAAskSmr+HRqVMn9ezZU8ePH9ejjz4qLy8vh/Vly5bNsuIAAAAAAADuhM0YYzKzgZNT2kkhNptNxhjZbDYlJydnWXHI2RISEuTn56f4+Hj5+vpmdzkAAAAAAIvLzO/QTM/wOHTo0B0XBgAAAAAAcD9kOvAoUqTIvagDAAAAAAAgy2Q68Jg2bdot17dt2/aOiwEAAAAAAMgKmb6GR548eRweX716VRcuXJCbm5ty5cqlM2fOZGmByLm4hgcAAAAA4H7KzO/QTN+W9uzZsw7L+fPntXfvXlWtWlUzZ86846IBAAAAAACySqZneNzMtm3b1Lp1a+3ZsycrdocHQGqyNuCHg/Lw9rnr/fWJzJcFVQEAAAAArOqezvC4GWdnZ/35559ZtTsAAAAAAIA7lumLli5YsMDhsTFGJ06c0JgxY1SlSpUsKwwAAAAAAOBOZTrwaNSokcNjm82m/Pnzq2bNmhoxYkRW1QUAAAAAAHDHMh14pKSk3Is6AAAAAAAAskymr+Hxzjvv6MKFC2naL168qHfeeSdLigIAAAAAALgbmQ48Bg0apPPnz6dpv3DhggYNGpQlRQEAAAAAANyNTAcexhjZbLY07Tt27FDevHmzpCgAAAAAAIC7keFreOTJk0c2m002m00lSpRwCD2Sk5N1/vx5vfrqq/ekSAAAAAAAgMzIcOAxcuRIGWPUoUMHDRo0SH5+fvZ1bm5uCgkJUeXKle9JkQAAAAAAAJmR4cCjXbt2kqTQ0FA98cQTcnV1vWdFAQAAAAAA3I1M35a2WrVq9j9fvHhRV69edVjv6+t791UBAAAAAADchUxftPTChQvq0qWLChQoIG9vb+XJk8dhySlOnjypbt26KSwsTB4eHipYsKCqVq2qcePGpXtb3Zzs+PHjcnNzU3h4eHaXAgAAAADAAyHTgcebb76pVatWaezYsXJ3d9fEiRM1aNAgFSpUSNOmTbsXNWbawYMHFRkZqWXLlum9997TL7/8ohUrVuiNN97QwoULtWLFijvab3JyslJSUrK42tubMmWKmjVrpgsXLmjDhg237X/jrBsAAAAAAP5tMh14LFy4UGPHjlWTJk3k4uKiJ598Uv/73//03nvvacaMGfeixkzr1KmTXFxctG3bNjVr1kylSpVSmTJl9Pzzz+u7775TgwYNJEkfffSRypQpIy8vLwUHB6tTp046f/68fT9TpkxR7ty5tWjRIkVERMjd3V1HjhzR1q1bVbt2beXLl09+fn6qVq2afv75Z4ca9uzZo6pVq8rDw0MRERFasWKFbDab5s+fb+/zxx9/qHnz5sqTJ4/8/f3VsGFDHT582GE/xhhNnjxZbdq0UcuWLRUTE+Ow/vDhw7LZbJozZ46qV68uDw8PffHFF5KkyZMnq1SpUvLw8FB4eLjGjh3rsG3v3r1VokQJ5cqVS0WLFlX//v0JSwAAAAAAlpDpwOPMmTMKDQ2VdO16HWfOnJEkVa1aVT/88EPWVncH4uLitGzZMnXu3FleXl7p9km9pa6Tk5M++eQT7dq1S1OnTtWqVav01ltvOfS9cOGChg4dqokTJ+q3335TgQIF9M8//6hdu3Zat26dfvzxRxUvXlz16tXTP//8I0lKSUlRo0aNlCtXLm3evFmff/65+vXrl2a/NWrUkLe3t3744QetX79e3t7eqlu3rq5cuWLvt3r1al24cEG1atVSmzZtNGfOHPs41+vdu7e6du2q2NhYRUVFacKECerXr5+GDBmi2NhYvffee+rfv7+mTp1q38bHx0dTpkzR7t27NWrUKE2YMEEff/zxTZ/by5cvKyEhwWEBAAAAACAnyvRFS4sWLarDhw+rSJEiioiI0Jw5c1SpUiUtXLhQuXPnvgclZs7+/ftljFHJkiUd2vPly6dLly5Jkjp37qwPPvhA3bt3t68PDQ3V4MGD9dprrznMhLh69arGjh2rcuXK2dtq1qzpsO/x48crT548Wrt2rerXr69ly5bpwIEDWrNmjQICAiRJQ4YMUe3ate3bzJo1S05OTpo4caI9gJk8ebJy586tNWvWqE6dOpKkmJgYtWjRQs7Oznr44YcVFham2bNn66WXXnKooXv37nruuefsjwcPHqwRI0bY20JDQ7V7926NHz/efsed//3vf/b+ISEh6tmzp2bPnp0m9Ek1dOhQDRo0KN11AAAAAADkJJme4dG+fXvt2LFDktS3b1/7tTzeeOMNvfnmm1le4J1KDRFSbdmyRdu3b9fDDz+sy5cvS7o2e6J27doKCgqSj4+P2rZtq7i4OCUmJtq3c3NzU9myZR32derUKb366qsqUaKE/Pz85Ofnp/Pnz+vo0aOSpL179yo4ONgedkhSpUqVHPbx008/af/+/fLx8ZG3t7e8vb2VN29eXbp0SQcOHJAknTt3TnPnzlXr1q3t27Vu3VqTJk1Kc7wVKlSw//n06dM6duyYXnzxRfu+vb299e6779r3LUlff/21qlatqoCAAHl7e6t///72Y0hP3759FR8fb1+OHTt2074AAAAAAGSnTM/weOONN+x/rlGjhvbs2aNt27apWLFiDrMgsktYWJhsNpv27Nnj0F60aFFJkqenpyTpyJEjqlevnl599VUNHjxYefPm1fr16/Xiiy86XMfC09MzTXgSHR2t06dPa+TIkSpSpIjc3d1VuXJl+6koxpg029woJSVFjz76aLrXPcmfP78k6csvv9SlS5f02GOP2dcZY5SSkqLdu3crIiLC3n796TupF1adMGGCw7aS5OzsLEn68ccf1aJFCw0aNEhRUVHy8/PTrFmzNGLEiJvW7O7uLnd391seFwAAAAAAOUGmA4/rXbp0SYULF1bhwoWzqp675u/vr9q1a2vMmDF6/fXXb3odj23btikpKUkjRoyQk9O1iS5z5szJ0Bjr1q3T2LFjVa9ePUnSsWPH9Pfff9vXh4eH6+jRo/rrr79UsGBBSdLWrVsd9vHII49o9uzZKlCggHx9fdMdJyYmRj179lR0dLRDe9euXTVp0iQNHz483e0KFiyooKAgHTx4UK1atUq3z4YNG1SkSBGHa4scOXLk1gcOAAAAAMADItOntCQnJ2vw4MEKCgqSt7e3Dh48KEnq379/mjuIZJexY8cqKSlJFSpU0OzZsxUbG6u9e/fqiy++0J49e+Ts7KxixYopKSlJo0eP1sGDBzV9+nSNGzcuQ/sPCwvT9OnTFRsbq82bN6tVq1b2mSOSVLt2bRUrVkzt2rXTr7/+qg0bNtiDhdSZH61atVK+fPnUsGFDrVu3TocOHdLatWvVrVs3HT9+XNu3b9fPP/+sl156SaVLl3ZYXnjhBU2bNu2Wd1QZOHCghg4dqlGjRmnfvn3auXOnJk+erI8++sh+DEePHtWsWbN04MABffLJJ5o3b96dPuUAAAAAAOQomQ48hgwZoilTpujDDz+Um5ubvb1MmTKaOHFilhZ3p4oVK6ZffvlFtWrVUt++fVWuXDlVqFBBo0ePVq9evTR48GCVL19eH330kT744AOVLl1aM2bM0NChQzO0/0mTJuns2bOKjIxUmzZt1LVrVxUoUMC+3tnZWfPnz9f58+dVsWJFvfTSS/YLhHp4eEiScuXKpR9++EGFCxfWc889p1KlSqlDhw66ePGifH19FRMTo4iICIWHh6cZv1GjRjpz5owWLlx40xpfeuklTZw4UVOmTFGZMmVUrVo1TZkyxX6HnYYNG+qNN95Qly5dVL58eW3cuFH9+/fP8HMMAAAAAEBOZjPGmMxsEBYWpvHjx+vpp5+Wj4+PduzYoaJFi2rPnj2qXLmyzp49e69qfaBt2LBBVatW1f79+1WsWLHsLidLJCQkyM/PTwN+OCgPb5+73l+fyHxZUBUAAAAAwKpSf4fGx8ff9PIQqTJ9DY8//vhDYWFhadpTUlJueYrFv828efPk7e2t4sWLa//+/erWrZuqVKlimbADAAAAAICcLNOntDz88MNat25dmvavvvpKkZGRWVKUFfzzzz/q1KmTwsPDFR0drYoVK+rbb7/N7rIAAAAAAPhXyPQMjwEDBqhNmzb6448/lJKSorlz52rv3r2aNm2aFi1adC9qfCC1bdtWbdu2ze4yAAAAAAD4V8r0DI8GDRpo9uzZWrx4sWw2m95++23FxsZq4cKFql279r2oEQAAAAAAIFMyPMPj4MGDCg0Nlc1mU1RUlKKiou5lXQAAAAAAAHcswzM8ihcvrtOnT9sfN2/eXH/99dc9KQoAAAAAAOBuZDjwuPHutYsXL1ZiYmKWFwQAAAAAAHC3Mn0NDwAAAAAAgJwuw9fwsNlsstlsadqAHuX85evrm91lAAAAAABgl+HAwxij6Ohoubu7S5IuXbqkV199VV5eXg795s6dm7UVAgAAAAAAZFKGA4927do5PG7dunWWFwMAAAAAAJAVMhx4TJ48+V7WAQAAAAAAkGW4aCkAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByXLK7ADz4PtoRJw/vK3e9nz6R+bKgGgAAAAAAmOEBAAAAAAAsiMADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BRxaJjo5Wo0aN7mjb6tWrq3v37jddX6dOHTk7O+vHH3+8s+IAAAAAAPiXIfDI4Y4ePapNmzapS5cuiomJuW3/K1eu3IeqAAAAAADI2Qg87oO1a9eqUqVKcnd3V2BgoPr06aOkpCRJ12aGrF27VqNGjZLNZpPNZtPhw4ft206ePFn169fXa6+9ptmzZysxMdFh39WrV1eXLl3Uo0cP5cuXT7Vr15Yk7d69W/Xq1ZO3t7cKFiyoNm3a6O+//7Zvt2TJElWtWlW5c+eWv7+/6tevrwMHDtz7JwMAAAAAgPuAwOMe++OPP1SvXj1VrFhRO3bs0GeffaaYmBi9++67kqRRo0apcuXKevnll3XixAmdOHFCwcHBkiRjjCZPnqzWrVsrPDxcJUqU0Jw5c9KMMXXqVLm4uGjDhg0aP368Tpw4oWrVqql8+fLatm2blixZor/++kvNmjWzb5OYmKgePXpo69atWrlypZycnNS4cWOlpKTc9FguX76shIQEhwUAAAAAgJzIJbsLsLqxY8cqODhYY8aMkc1mU3h4uP7880/17t1bb7/9tvz8/OTm5qZcuXIpICDAYdsVK1bowoULioqKkiS1bt1aMTExat++vUO/sLAwffjhh/bHb7/9th555BG999579rZJkyYpODhY+/btU4kSJfT888877CMmJkYFChTQ7t27Vbp06XSPZejQoRo0aNBdPR8AAAAAANwPzPC4x2JjY1W5cmXZbDZ7W5UqVXT+/HkdP378ltvGxMSoefPmcnG5lku98MIL2rx5s/bu3evQr0KFCg6Pf/rpJ61evVre3t72JTw8XJLsp60cOHBALVu2VNGiReXr66vQ0FBJ164ZcjN9+/ZVfHy8fTl27FgGnwUAAAAAAO4vZnjcY8YYh7AjtU1SmvbrnTlzRvPnz9fVq1f12Wef2duTk5M1adIkffDBB/Y2Ly8vh21TUlLUoEEDhz6pAgMDJUkNGjRQcHCwJkyYoEKFCiklJUWlS5e+5UVP3d3d5e7ufoujBQAAAAAgZyDwuMciIiL0zTffOAQfGzdulI+Pj4KCgiRJbm5uSk5OdthuxowZeuihhzR//nyH9pUrV2ro0KEaMmSIfebHjR555BF98803CgkJSbdPXFycYmNjNX78eD355JOSpPXr19/toQIAAAAAkGNwSksWio+P1/bt2x2WV155RceOHdPrr7+uPXv26Ntvv9WAAQPUo0cPOTlde/pDQkK0efNmHT58WH///bdSUlIUExOjJk2aqHTp0g5Lhw4ddO7cOX333Xc3raNz5846c+aMXnjhBW3ZskUHDx7UsmXL1KFDByUnJytPnjzy9/fX559/rv3792vVqlXq0aPH/XqaAAAAAAC45wg8stCaNWsUGRnpsAwYMECLFy/Wli1bVK5cOb366qt68cUX9b///c++Xa9eveTs7KyIiAjlz59fv/zyi3bs2JHmwqKS5OPjozp16igmJuamdRQqVEgbNmxQcnKyoqKiVLp0aXXr1k1+fn5ycnKSk5OTZs2apZ9++kmlS5fWG2+8oWHDht2T5wQAAAAAgOxgM6kXlAAyKSEhQX5+fhrww0F5ePvc9f76RObLgqoAAAAAAFaV+js0Pj5evr6+t+zLDA8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOS7ZXQAefD3K+cvX1ze7ywAAAAAAwI4ZHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACzHJbsLwIPvox1x8vC+clf76BOZL4uqAQAAAACAGR4AAAAAAMCCCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5fzrAo/o6Gg1atQo2/eRE02ZMkW5c+fO7jIAAAAAALhrlgs80gsjvv76a3l4eOjDDz/UqFGjNGXKFPu66tWrq3v37ve1xsw4c+aMunfvrpCQELm5uSkwMFDt27fX0aNHs7s0AAAAAAByLMsFHjeaOHGiWrVqpTFjxuitt96Sn5/fAzOL4cyZM3r88ce1YsUKjR07Vvv379fs2bN14MABVaxYUQcPHszuEgEAAAAAyJEsHXh8+OGH6tKli7788ku99NJLkhxngERHR2vt2rUaNWqUbDabbDabDh8+LEn67bff9Oyzz8rX11c+Pj568skndeDAAYf9Dx8+XIGBgfL391fnzp119epV+7orV67orbfeUlBQkLy8vPTYY49pzZo19vWpp48sXbpUpUqVkre3t+rWrasTJ07Y+/Tr109//vmnVqxYoXr16qlw4cJ66qmntHTpUrm6uqpz5872viEhIRo5cqRDfeXLl9fAgQPtjz/66COVKVNGXl5eCg4OVqdOnXT+/Pm7eIYBAAAAAMiZLBt49OnTR4MHD9aiRYv0/PPPp9tn1KhRqly5sl5++WWdOHFCJ06cUHBwsP744w899dRT8vDw0KpVq/TTTz+pQ4cOSkpKsm+7evVqHThwQKtXr9bUqVM1ZcoUh1Nl2rdvrw0bNmjWrFn69ddf1bRpU9WtW1e///67vc+FCxc0fPhwTZ8+XT/88IOOHj2qXr16SZJSUlI0a9YstWrVSgEBAQ51e3p6qlOnTlq6dKnOnDmT4efEyclJn3zyiXbt2qWpU6dq1apVeuuttzK8/eXLl5WQkOCwAAAAAACQE7lkdwH3wvfff69vv/1WK1euVM2aNW/az8/PT25ubsqVK5dDqPDpp5/Kz89Ps2bNkqurqySpRIkSDtvmyZNHY8aMkbOzs8LDw/Xss89q5cqVevnll3XgwAHNnDlTx48fV6FChSRJvXr10pIlSzR58mS99957kqSrV69q3LhxKlasmCSpS5cueueddyRJp0+f1rlz51SqVKl0ay9VqpSMMdq/f78qVaqUoefl+muVhIaGavDgwXrttdc0duzYDG0/dOhQDRo0KEN9AQAAAADITpac4VG2bFmFhITo7bff1j///JPp7bdv364nn3zSHnak5+GHH5azs7P9cWBgoE6dOiVJ+vnnn2WMUYkSJeTt7W1f1q5d63BaTK5cuexhx437uB1jjCTJzc0tw8e1evVq1a5dW0FBQfLx8VHbtm0VFxenxMTEDG3ft29fxcfH25djx45leGwAAAAAAO4nS87wCAoK0jfffKMaNWqobt26WrJkiXx8fDK8vaen52373BiG2Gw2paSkSLp2Ooqzs7N++uknh1BEkry9vW+5j9QgI3/+/MqdO7d2796d7vh79uyRi4uLQkNDJV07XSV121TXX1PkyJEjqlevnl599VUNHjxYefPm1fr16/Xiiy869LsVd3d3ubu7Z6gvAAAAAADZyZIzPCSpcOHCWrt2rU6dOqU6derc9HoTbm5uSk5OdmgrW7as1q1bl+Eg4EaRkZFKTk7WqVOnFBYW5rDceD2Om3FyclKzZs305Zdf6uTJkw7rLl68qLFjx6px48by8/OTdC0guf6CpwkJCTp06JD98bZt25SUlKQRI0bo8ccfV4kSJfTnn3/e0fEBAAAAAJDTWTbwkKSHHnpIa9asUVxcnOrUqaP4+Pg0fUJCQrR582YdPnxYf//9t1JSUtSlSxclJCSoRYsW2rZtm37//XdNnz5de/fuzdC4JUqUUKtWrdS2bVvNnTtXhw4d0tatW/XBBx9o8eLFGa5/yJAhCggIUO3atfX999/r2LFj+uGHHxQVFSUnJyeNGjXK3rdmzZqaPn261q1bp127dqldu3YOs0uKFSumpKQkjR49WgcPHtT06dM1bty4DNcCAAAAAMCDxNKBh3Tt9Ja1a9fq3Llzql27ts6dO+ewvlevXnJ2dlZERITy58+vo0ePyt/fX6tWrdL58+dVrVo1Pfroo5owYcItr+lxo8mTJ6tt27bq2bOnSpYsqf/85z/avHmzgoODM7yPfPny6ccff1SNGjXUsWNHhYaGqlq1akpOTtb27dsVGBho79u3b1899dRTql+/vurVq6dGjRo5XB+kfPny+uijj/TBBx+odOnSmjFjhoYOHZrhWgAAAAAAeJDYzI0XfkCOFhMTo06dOmn27Nlq1KhRttaSkJAgPz8/DfjhoDy8M36NlPT0icyXRVUBAAAAAKwq9XdofHy8fH19b9nX8jM8rObFF1/UrFmzFBsbq4sXL2Z3OQAAAAAA5EiWvEuL1TVu3Di7SwAAAAAAIEdjhgcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWw21pcdd6lPOXr69vdpcBAAAAAIAdMzwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHJfsLgAPvo92xMnD+8odb98nMl8WVgMAAAAAADM8AAAAAACABRF4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeFjAyZMnVbt2bXl5eSl37tzZXQ4AAAAAANnuXxV4REdHy2az2Rd/f3/VrVtXv/766z0bc+DAgSpfvnyadpvNpvnz56dp7969u6pXr56pMT7++GOdOHFC27dv1759+yRJv/zyi+rXr68CBQrIw8NDISEhat68uf7++29J0uHDhx2ei9SldevWmT1EAAAAAABynH9V4CFJdevW1YkTJ3TixAmtXLlSLi4uql+/fnaXdVcOHDigRx99VMWLF1eBAgV06tQp1apVS/ny5dPSpUsVGxurSZMmKTAwUBcuXHDYdsWKFfbn48SJE/r000+z6SgAAAAAAMg6/7rAw93dXQEBAQoICFD58uXVu3dvHTt2TKdPn9aVK1fUpUsXBQYG2mdFDB061L6tzWbT+PHjVb9+feXKlUulSpXSpk2btH//flWvXl1eXl6qXLmyDhw4IEmaMmWKBg0apB07dthnUEyZMiVT9VavXl1du3bVW2+9pbx58yogIEADBw60rw8JCdE333yjadOmyWazKTo6Whs3blRCQoImTpyoyMhIhYaGqmbNmho5cqQKFy7ssH9/f3/78xEQECA/P787fm4BAAAAAMgp/nWBx/XOnz+vGTNmKCwsTP7+/vrkk0+0YMECzZkzR3v37tUXX3yhkJAQh20GDx6stm3bavv27QoPD1fLli3VsWNH9e3bV9u2bZMkdenSRZLUvHlz9ezZUw8//LB9BkXz5s0zXefUqVPl5eWlzZs368MPP9Q777yj5cuXS5K2bt2qunXrqlmzZjpx4oRGjRqlgIAAJSUlad68eTLG3N2TdJ3Lly8rISHBYQEAAAAAICdyye4C7rdFixbJ29tbkpSYmKjAwEAtWrRITk5OOnr0qIoXL66qVavKZrOpSJEiabZv3769mjVrJknq3bu3KleurP79+ysqKkqS1K1bN7Vv316S5OnpKW9vb7m4uCggIOCOay5btqwGDBggSSpevLjGjBmjlStXqnbt2sqfP7/c3d3l6elpH+Pxxx/Xf//7X7Vs2VKvvvqqKlWqpJo1a6pt27YqWLCgw76feOIJOTn9X+61bt06RUZGplvH0KFDNWjQoDs+DgAAAAAA7pd/3QyPGjVqaPv27dq+fbs2b96sOnXq6JlnntGRI0cUHR2t7du3q2TJkuratauWLVuWZvuyZcva/5waHpQpU8ah7dKlS1k6++H6MSUpMDBQp06duuU2Q4YM0cmTJzVu3DhFRERo3LhxCg8P186dOx36zZ492/58bN++XRERETfdZ9++fRUfH29fjh07ducHBQAAAADAPfSvCzy8vLwUFhamsLAwVapUSTExMUpMTNSECRP0yCOP6NChQxo8eLAuXryoZs2aqUmTJg7bu7q62v9ss9lu2paSknLLOnx8fBQfH5+m/dy5c2muo3H9/lPHuN3+pWvX52jatKlGjBih2NhYFSpUSMOHD3foExwcbH8+wsLC5O7uftP9ubu7y9fX12EBAAAAACAn+tcFHjey2WxycnLSxYsXJUm+vr5q3ry5JkyYoNmzZ+ubb77RmTNn7nj/bm5uSk5OTtMeHh6urVu3OrQZY/TTTz+pZMmSdzzereooVqyYEhMTs3zfAAAAAADkNP+6a3hcvnxZJ0+elCSdPXtWY8aM0fnz59WgQQN9/PHHCgwMVPny5eXk5KSvvvpKAQEByp079x2PFxISokOHDmn79u166KGH5OPjI3d3d/Xq1Uvt2rVTeHi46tSpo4sXL+rzzz/XgQMH1Llz57s6xkWLFmnWrFlq0aKFSpQoIWOMFi5cqMWLF2vy5Ml3tW8AAAAAAB4E/7rAY8mSJQoMDJR07bSS8PBwffXVV6pevbp+//13ffDBB/r999/l7OysihUravHixQ4X9cys559/XnPnzlWNGjV07tw5TZ48WdHR0WrWrJmMMRo+fLj69esnDw8PRUZGat26deleLDUzIiIilCtXLvXs2VPHjh2Tu7u7ihcvrokTJ6pNmzZ3tW8AAAAAAB4ENpOV9y3Fv0pCQoL8/Pw04IeD8vD2ueP99InMl4VVAQAAAACsKvV3aHx8/G2vK/mvv4YHAAAAAACwHgIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsByX7C4AD74e5fzl6+ub3WUAAAAAAGDHDA8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsh8ADAAAAAABYDoEHAAAAAACwHAIPAAAAAABgOQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDkEHgAAAAAAwHIIPAAAAAAAgOUQeAAAAAAAAMsh8AAAAAAAAJZD4AEAAAAAACyHwAMAAAAAAFgOgQcAAAAAALAcAg8AAAAAAGA5BB4AAAAAAMByCDwAAAAAAIDlEHgAAAAAAADLIfAAAAAAAACWQ+ABAAAAAAAsxyW7C8CD76MdcfLwvnJH2/aJzJfF1QAAAAAAwAwPAAAAAABgQQQeAAAAAADAcgg8AAAAAACA5RB4AAAAAAAAyyHwAAAAAAAAlkPgAQAAAAAALIfAAwAAAAAAWA6BBwAAAAAAsBwCDwAAAAAAYDmWDzxCQkI0cuTIDPc/fPiwbDabtm/fftM+U6ZMUe7cue+6tvQMHDhQ5cuXvyf7vp3q1aure/fu2TI2AAAAAABZKccGHtHR0bLZbHr//fcd2ufPny+bzZbh/WzdulWvvPJKVpcHAAAAAABysBwbeEiSh4eHPvjgA509e/aO95E/f37lypUrC6u6d65evZrdJQAAAAAAYAk5OvCoVauWAgICNHTo0Jv22bhxo5566il5enoqODhYXbt2VWJion39jae07NmzR1WrVpWHh4ciIiK0YsUK2Ww2zZ8/32G/Bw8eVI0aNZQrVy6VK1dOmzZtSjP2/PnzVaJECXl4eKh27do6duyYw/rPPvtMxYoVk5ubm0qWLKnp06c7rLfZbBo3bpwaNmwoLy8vvfvuu/Z106dPV0hIiPz8/NSiRQv9888/9nWXL19W165dVaBAAXl4eKhq1araunWrw77Xrl2rSpUqyd3dXYGBgerTp4+SkpLs6xMTE9W2bVt5e3srMDBQI0aMuOlzDAAAAADAgyZHBx7Ozs567733NHr0aB0/fjzN+p07dyoqKkrPPfecfv31V82ePVvr169Xly5d0t1fSkqKGjVqpFy5cmnz5s36/PPP1a9fv3T79uvXT7169dL27dtVokQJvfDCCw6BwYULFzRkyBBNnTpVGzZsUEJCglq0aGFfP2/ePHXr1k09e/bUrl271LFjR7Vv316rV692GGfAgAFq2LChdu7cqQ4dOkiSDhw4oPnz52vRokVatGiR1q5d63Bqz1tvvaVvvvlGU6dO1c8//6ywsDBFRUXpzJkzkqQ//vhD9erVU8WKFbVjxw599tlniomJcQhU3nzzTa1evVrz5s3TsmXLtGbNGv3000+3fD0uX76shIQEhwUAAAAAgJwoRwcektS4cWOVL19eAwYMSLNu2LBhatmypbp3767ixYvriSee0CeffKJp06bp0qVLafovW7ZMBw4c0LRp01SuXDlVrVpVQ4YMSXfcXr166dlnn1WJEiU0aNAgHTlyRPv377evv3r1qsaMGaPKlSvr0Ucf1dSpU7Vx40Zt2bJFkjR8+HBFR0erU6dOKlGihHr06KHnnntOw4cPdxinZcuW6tChg4oWLaoiRYpIuhbMTJkyRaVLl9aTTz6pNm3aaOXKlZKuzcz47LPPNGzYMD3zzDOKiIjQhAkT5OnpqZiYGEnS2LFjFRwcrDFjxig8PFyNGjXSoEGDNGLECKWkpOj8+fOKiYnR8OHDVbt2bZUpU0ZTp05VcnLyLV+LoUOHys/Pz74EBwffsj8AAAAAANklxwcekvTBBx9o6tSp2r17t0P7Tz/9pClTpsjb29u+REVFKSUlRYcOHUqzn7179yo4OFgBAQH2tkqVKqU7ZtmyZe1/DgwMlCSdOnXK3ubi4qIKFSrYH4eHhyt37tyKjY2VJMXGxqpKlSoO+6xSpYp9farr95EqJCREPj4+DuOnjn3gwAFdvXrVYd+urq6qVKmSw9iVK1d2uLhrlSpVdP78eR0/flwHDhzQlStXVLlyZfv6vHnzqmTJkuk+F6n69u2r+Ph4+3LjKTwAAAAAAOQULtldQEY89dRTioqK0n//+19FR0fb21NSUtSxY0d17do1zTaFCxdO02aMyfAdXlxdXe1/Tt0mJSXFoU96+7q+7cb16Y3v5eV1y7FT95M6tjHmtvtOb5zrt0v9c2a5u7vL3d39jrYFAAAAAOB+eiBmeEjS+++/r4ULF2rjxo32tkceeUS//fabwsLC0ixubm5p9hEeHq6jR4/qr7/+srfdeLHPjEpKStK2bdvsj/fu3atz584pPDxcklSqVCmtX7/eYZuNGzeqVKlSdzReqtRju37fV69e1bZt2+z7joiI0MaNGx2CjY0bN8rHx0dBQUEKCwuTq6urfvzxR/v6s2fPat++fXdVGwAAAAAAOcUDE3iUKVNGrVq10ujRo+1tvXv31qZNm9S5c2f9v/buP6iqOv/j+OvCBa4g965C0g/zR6awmj8QTYgMd8cfrTWtbbNouiaGTdaGuBZGqYHpOjat+8PKzaUCt1llt9RiJjNrG/2SSKbAZMKuqLkxO7rqpgk2ldHn+4fLna4gcfGe8J77fMzcGe45n/vxc+7Lt8N9e+45NTU1qq+vV1lZmXJyctqcY8KECRowYIBmzZqlDz/8UDt37vRetLSjZ360iIiIUE5Ojt5//31VVVVp9uzZSk1N9X5FJi8vTyUlJXr++edVX1+v3/72t9q0aZMeeeSRTr4D58XExOiBBx5QXl6etm7dqtraWt133336/PPPlZ2dLUl68MEH1dDQoJycHP3jH//Q66+/roKCAi1YsEBhYWHq3r27srOzlZeXp7///e/66KOPlJWVpbCwoPnrAAAAAABAu4LqE+6yZct8zloYNmyYduzYofr6eo0dO1bJyclasmSJ95obFwoPD9drr72mpqYmjR49WnPmzNHixYslSS6Xy6+1REdH69FHH9X06dOVlpambt26qbS01Lt/ypQp+sMf/qCnn35aQ4YM0dq1a1VcXKxx48b5f+AXWLlype666y7NnDlTI0eO1MGDB/XWW2+pR48ekqRrrrlGW7Zs0e7duzV8+HDNnTtX2dnZ3mOVzl/w9ZZbbtEdd9yh8ePH6+abb1ZKSsolrw0AAAAAgMuBw3T2gg42sXPnTt188806ePCgBgwY0NXLCSpnzpyRx+NRwf8dlqt77He/oA35yfEBXhUAAAAAwK5aPod+9tlncrvd7Y4NiouWBtLmzZvVvXt3DRw4UAcPHlRubq7S09NpdgAAAAAAYCMh1/BobGzUwoUL1dDQoPj4eI0fP16rVq3q6mUBAAAAAIAACrmGxz333KN77rmnq5cBAAAAAAAsFFQXLQUAAAAAAOgIGh4AAAAAAMB2aHgAAAAAAADboeEBAAAAAABsh4YHAAAAAACwnZC7SwsCb8HwOLnd7q5eBgAAAAAAXpzhAQAAAAAAbIeGBwAAAAAAsB0aHgAAAAAAwHZoeAAAAAAAANuh4QEAAAAAAGyHhgcAAAAAALAdGh4AAAAAAMB2aHgAAAAAAADboeEBAAAAAABsh4YHAAAAAACwHRoeAAAAAADAdmh4AAAAAAAA26HhAQAAAAAAbIeGBwAAAAAAsB1nVy8AwcsYI0k6c+ZMF68EAAAAABAKWj5/tnwebQ8ND3Taf//7X0nStdde28UrAQAAAACEksbGRnk8nnbH0PBAp/Xs2VOS9Mknn3znXzRcHs6cOaNrr71WDQ0NcrvdXb0cdACZBR8yCz5kFpzILfiQWfAhs+ATCpkZY9TY2Kirr776O8fS8ECnhYWdvwSMx+OxbTHZldvtJrMgQ2bBh8yCD5kFJ3ILPmQWfMgs+Ng9s47+hzsXLQUAAAAAALZDwwMAAAAAANgODQ90WlRUlAoKChQVFdXVS0EHkVnwIbPgQ2bBh8yCE7kFHzILPmQWfMjMl8N05F4uAAAAAAAAQYQzPAAAAAAAgO3Q8AAAAAAAALZDwwMAAAAAANgODQ8AAAAAAGA7NDzgY82aNerfv79cLpdSUlJUXl7e7vgdO3YoJSVFLpdL1113nZ5//vlWYzZu3KjBgwcrKipKgwcP1ubNm61afkgKdGYlJSVyOBytHl988YWVhxFS/Mns6NGjmj59uhITExUWFqb58+e3OY46s1agM6POrOdPZps2bdKECRN0xRVXyO12Ky0tTW+99VarcdSZtQKdGXVmPX8ye++995Senq64uDh169ZNSUlJ+t3vftdqHHVmrUBnRp1Zz9/f9Vvs3LlTTqdTI0aMaLUvpOrMAP9TWlpqIiIiTFFRkamtrTW5ubkmJibG/Otf/2pz/OHDh010dLTJzc01tbW1pqioyERERJhXX33VO6aiosKEh4ebFStWmLq6OrNixQrjdDpNZWXl93VYtmZFZsXFxcbtdpujR4/6PBAY/mb28ccfm3nz5pl169aZESNGmNzc3FZjqDNrWZEZdWYtfzPLzc01Tz31lNm9e7c5cOCAeeyxx0xERISpqqryjqHOrGVFZtSZtfzNrKqqyqxfv9589NFH5uOPPzYvv/yyiY6ONmvXrvWOoc6sZUVm1Jm1/M2sxenTp811111nJk6caIYPH+6zL9TqjIYHvG688UYzd+5cn21JSUkmPz+/zfELFy40SUlJPtvuv/9+k5qa6n2emZlpbr31Vp8xkyZNMtOmTQvQqkObFZkVFxcbj8cT8LXiPH8z+7aMjIw2PzxTZ9ayIjPqzFqXklmLwYMHm6VLl3qfU2fWsiIz6sxagcjszjvvNL/4xS+8z6kza1mRGXVmrc5mNnXqVLN48WJTUFDQquERanXGV1ogSfrqq6+0d+9eTZw40Wf7xIkTVVFR0eZrdu3a1Wr8pEmTtGfPHp07d67dMRebEx1nVWaS1NTUpL59+6p37966/fbbVV1dHfgDCEGdyawjqDPrWJWZRJ1ZJRCZffPNN2psbFTPnj2926gz61iVmUSdWSUQmVVXV6uiokIZGRnebdSZdazKTKLOrNLZzIqLi3Xo0CEVFBS0uT/U6oyGByRJJ0+eVHNzsxISEny2JyQk6NixY22+5tixY22O//rrr3Xy5Ml2x1xsTnScVZklJSWppKREZWVl2rBhg1wul9LT01VfX2/NgYSQzmTWEdSZdazKjDqzTiAyW7Vqlc6ePavMzEzvNurMOlZlRp1Z51Iy6927t6KiojRq1Cj98pe/1Jw5c7z7qDPrWJUZdWadzmRWX1+v/Px8/eUvf5HT6WxzTKjVWdvvAkKWw+HweW6MabXtu8ZfuN3fOeGfQGeWmpqq1NRU7/709HSNHDlSzzzzjFavXh2oZYc0K2qCOrNWoN9f6sx6nc1sw4YNKiws1Ouvv65evXoFZE50TKAzo86s15nMysvL1dTUpMrKSuXn5+v666/X3XfffUlzouMCnRl1Zr2OZtbc3Kzp06dr6dKlGjRoUEDmtAMaHpAkxcfHKzw8vFVn7/jx4606gC2uvPLKNsc7nU7FxcW1O+Zic6LjrMrsQmFhYRo9ejSd+gDoTGYdQZ1Zx6rMLkSdBc6lZPbXv/5V2dnZeuWVVzR+/HiffdSZdazK7ELUWeBcSmb9+/eXJA0dOlT/+c9/VFhY6P3wTJ1Zx6rMLkSdBY6/mTU2NmrPnj2qrq7WQw89JOn81/2MMXI6ndq2bZt+/OMfh1yd8ZUWSJIiIyOVkpKit99+22f722+/rZtuuqnN16SlpbUav23bNo0aNUoRERHtjrnYnOg4qzK7kDFGNTU1uuqqqwKz8BDWmcw6gjqzjlWZXYg6C5zOZrZhwwZlZWVp/fr1uu2221rtp86sY1VmF6LOAidQ/zYaY/Tll196n1Nn1rEqs7b2U2eB4W9mbrdb+/btU01Njfcxd+5cJSYmqqamRmPGjJEUgnX2PV4gFZe5ltsevfjii6a2ttbMnz/fxMTEmCNHjhhjjMnPzzczZ870jm+5xemvfvUrU1tba1588cVWtzjduXOnCQ8PNytXrjR1dXVm5cqVtr7t0ffNiswKCwvN1q1bzaFDh0x1dbWZPXu2cTqd5v333//ej8+O/M3MGGOqq6tNdXW1SUlJMdOnTzfV1dVm//793v3UmbWsyIw6s5a/ma1fv944nU7z3HPP+dxW8fTp094x1Jm1rMiMOrOWv5k9++yzpqyszBw4cMAcOHDAvPTSS8btdptFixZ5x1Bn1rIiM+rMWp35HeTb2rpLS6jVGQ0P+HjuuedM3759TWRkpBk5cqTZsWOHd9+sWbNMRkaGz/jt27eb5ORkExkZafr162f++Mc/tprzlVdeMYmJiSYiIsIkJSWZjRs3Wn0YISXQmc2fP9/06dPHREZGmiuuuMJMnDjRVFRUfB+HEjL8zUxSq0ffvn19xlBn1gp0ZtSZ9fzJLCMjo83MZs2a5TMndWatQGdGnVnPn8xWr15thgwZYqKjo43b7TbJyclmzZo1prm52WdO6sxagc6MOrOev7+DfFtbDQ9jQqvOHMb874qFAAAAAAAANsE1PAAAAAAAgO3Q8AAAAAAAALZDwwMAAAAAANgODQ8AAAAAAGA7NDwAAAAAAIDt0PAAAAAAAAC2Q8MDAAAAAADYDg0PAAAAAABgOzQ8AAAAAACA7dDwAAAAtpaVlaUpU6Z09TLadOTIETkcDtXU1HT1UgAAsB0aHgAAAF3gq6++6uolAABgazQ8AABAyBg3bpxycnI0f/589ejRQwkJCfrTn/6ks2fPavbs2YqNjdWAAQP05ptvel+zfft2ORwOvfHGGxo+fLhcLpfGjBmjffv2+cy9ceNGDRkyRFFRUerXr59WrVrls79fv35avny5srKy5PF4dN9996l///6SpOTkZDkcDo0bN06S9MEHH2jChAmKj4+Xx+NRRkaGqqqqfOZzOBx64YUXdOeddyo6OloDBw5UWVmZz5j9+/frtttuk9vtVmxsrMaOHatDhw559xcXF+uHP/yhXC6XkpKStGbNmkt+jwEAuFzQ8AAAACFl3bp1io+P1+7du5WTk6MHHnhAP//5z3XTTTepqqpKkyZN0syZM/X555/7vC4vL0+/+c1v9MEHH6hXr1664447dO7cOUnS3r17lZmZqWnTpmnfvn0qLCzUkiVLVFJS4jPH008/rRtuuEF79+7VkiVLtHv3bknSO++8o6NHj2rTpk2SpMbGRs2aNUvl5eWqrKzUwIEDNXnyZDU2NvrMt3TpUmVmZurDDz/U5MmTNWPGDH366aeSpH//+9+65ZZb5HK59O6772rv3r2699579fXXX0uSioqKtGjRIv36179WXV2dVqxYoSVLlmjdunUBf88BAOgKDmOM6epFAAAAWCUrK0unT5/Wa6+9pnHjxqm5uVnl5eWSpObmZnk8Hv3sZz/Tn//8Z0nSsWPHdNVVV2nXrl1KTU3V9u3b9aMf/UilpaWaOnWqJOnTTz9V7969VVJSoszMTM2YMUMnTpzQtm3bvH/uwoUL9cYbb2j//v2Szp/hkZycrM2bN3vHHDlyRP3791d1dbVGjBhx0WNobm5Wjx49tH79et1+++2Szp/hsXjxYi1btkySdPbsWcXGxmrLli269dZb9fjjj6u0tFT//Oc/FRER0WrOPn366KmnntLdd9/t3bZ8+XJt2bJFFRUVnXmrAQC4rHCGBwAACCnDhg3z/hweHq64uDgNHTrUuy0hIUGSdPz4cZ/XpaWleX/u2bOnEhMTVVdXJ0mqq6tTenq6z/j09HTV19erubnZu23UqFEdWuPx48c1d+5cDRo0SB6PRx6PR01NTfrkk08ueiwxMTGKjY31rrumpkZjx45ts9lx4sQJNTQ0KDs7W927d/c+li9f7vOVFwAAgpmzqxcAAADwfbqwAeBwOHy2ORwOSdI333zznXO1jDXGeH9u0dZJtDExMR1aY1ZWlk6cOKHf//736tu3r6KiopSWltbqQqdtHUvLurt163bR+VvGFBUVacyYMT77wsPDO7RGAAAudzQ8AAAAOqCyslJ9+vSRJJ06dUoHDhxQUlKSJGnw4MF67733fMZXVFRo0KBB7TYQIiMjJcnnLBBJKi8v15o1azR58mRJUkNDg06ePOnXeocNG6Z169bp3LlzrRojCQkJuuaaa3T48GHNmDHDr3kBAAgWNDwAAAA64Mknn1RcXJwSEhK0aNEixcfHa8qUKZKkhx9+WKNHj9ayZcs0depU7dq1S88+++x33vWkV69e6tatm7Zu3arevXvL5XLJ4/Ho+uuv18svv6xRo0bpzJkzysvLa/eMjbY89NBDeuaZZzRt2jQ99thj8ng8qqys1I033qjExEQVFhZq3rx5crvd+slPfqIvv/xSe/bs0alTp7RgwYLOvk0AAFw2uIYHAABAB6xcuVK5ublKSUnR0aNHVVZW5j1DY+TIkfrb3/6m0tJS3XDDDXriiSf05JNPKisrq905nU6nVq9erbVr1+rqq6/WT3/6U0nSSy+9pFOnTik5OVkzZ87UvHnz1KtXL7/WGxcXp3fffVdNTU3KyMhQSkqKioqKvGd7zJkzRy+88IJKSko0dOhQZWRkqKSkxHurXAAAgh13aQEAAGhHy11aTp06pR/84AddvRwAANBBnOEBAAAAAABsh4YHAAAAAACwHb7SAgAAAAAAbIczPAAAAAAAgO3Q8AAAAAAAALZDwwMAAAAAANgODQ8AAAAAAGA7NDwAAAAAAIDt0PAAAAAAAAC2Q8MDAAAAAADYDg0PAAAAAABgO/8Pf6NYYp9cwKoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map importances to the column names\n",
    "feature_importances = pd.Series(importances, index=X_train.columns)\n",
    "top_10 = feature_importances.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_10.plot(kind='barh', color='skyblue')\n",
    "plt.title('Top 10 Most Important Features from RandomForestRegressor')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.gca().invert_yaxis()  # to have the most important feature at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52053fde-74af-48f8-abee-4c6e1770644a",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cfa53-e984-491c-b31c-3f477959b48c",
   "metadata": {},
   "source": [
    "## Default parameters with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f64a446d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE = 21783.8234, R2 = 0.9128\n",
      "Fold 2: RMSE = 21257.5422, R2 = 0.9314\n",
      "Fold 3: RMSE = 21705.7428, R2 = 0.9095\n",
      "Fold 4: RMSE = 21774.2473, R2 = 0.9133\n",
      "Fold 5: RMSE = 21688.8447, R2 = 0.9022\n",
      "Mean RMSE: 21642.0401\n",
      "Mean R2: 0.9138\n"
     ]
    }
   ],
   "source": [
    "X = housing.drop(['SalePrice','DateSold'],axis=1) # Features\n",
    "y = housing['SalePrice']\n",
    "\n",
    "# Initialize the KFold cross-validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store RMSE and R2 scores for each fold\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create an XGBoost regressor model\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE for this fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "    \n",
    "    # Calculate R2 for this fold\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    # Display RMSE and R2 for this fold\n",
    "    print(f\"Fold {fold}: RMSE = {rmse:.4f}, R2 = {r2:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Calculate and print the mean RMSE and R2 across all folds\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "print(f\"Mean RMSE: {mean_rmse:.4f}\")\n",
    "print(f\"Mean R2: {mean_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd966d-dac6-4606-a53f-8d675ffcf709",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e27527d0-8832-452f-9629-839f859d5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "Best hyperparameters: {'alpha': 1, 'colsample_bytree': 1.0, 'gamma': 0.0, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0.0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'lambda': [0, 0.5, 1],\n",
    "    'alpha': [0, 0.5, 1]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6eeaeb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for each fold: [475231323.57400227, 255351613.35409096, 514992390.22673565, 400508035.73029065, 537202505.0930653]\n",
      "R^2 for each fold: [0.9227926453211305, 0.9412476200255651, 0.9171853947970594, 0.9276432769673071, 0.8967479286742865]\n",
      "Average MSE: 436657173.59563696\n",
      "Average R^2: 0.9211233731570697\n"
     ]
    }
   ],
   "source": [
    "#best_params = {\n",
    "#    'alpha': 0,\n",
    "#    'colsample_bytree': 1.0,\n",
    "#    'gamma': 0.0,\n",
    "#    'lambda': 1,\n",
    "#    'max_depth': 3,\n",
    "#    'min_child_weight': 5,\n",
    "#    'subsample': 1.0,\n",
    "#    'objective': 'reg:squarederror'  # This is the default for regression tasks in XGBoost\n",
    "#}\n",
    "#grid_search.best_params_\n",
    "model = xgb.XGBRegressor(**grid_search.best_params_)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "\n",
    "print(\"MSE for each fold:\", mse_scores)\n",
    "print(\"R^2 for each fold:\", r2_scores)\n",
    "print(\"Average MSE:\", sum(mse_scores) / len(mse_scores))\n",
    "print(\"Average R^2:\", sum(r2_scores) / len(r2_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb1741-c6d4-418e-8de3-75c78269521a",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c35096da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance\n",
      "16   OverallQual        0.43\n",
      "77       TotalSF        0.22\n",
      "53    GarageCars        0.05\n",
      "39    CentralAir        0.04\n",
      "46   KitchenQual        0.03\n",
      "28      BsmtQual        0.02\n",
      "56    GarageCond        0.02\n",
      "76           Age        0.02\n",
      "48    Fireplaces        0.01\n",
      "14      BldgType        0.01\n",
      "17   OverallCond        0.01\n",
      "11  Neighborhood        0.01\n",
      "18  YearRemodAdd        0.01\n",
      "79          Bath        0.01\n",
      "78      BsmtBath        0.01\n",
      "10     LandSlope        0.01\n",
      "32    BsmtFinSF1        0.01\n",
      "62   ScreenPorch        0.01\n",
      "57    PavedDrive        0.00\n",
      "4        LotArea        0.00\n",
      "25     ExterQual        0.00\n",
      "2       MSZoning        0.00\n",
      "54    GarageArea        0.00\n",
      "23    MasVnrType        0.00\n",
      "6          Alley        0.00\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost regressor model (if you haven't already)\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "model.fit(X, y)\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00791d53-9945-4861-b4ce-cf874da4efcc",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42680b5c-dcb7-4a8f-bc64-f60a7dbd5ab1",
   "metadata": {},
   "source": [
    "## First run with no tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8e43354-dc2c-464f-8c9e-97ab7bfed7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average R^2 Score across the 5 folds: 0.9241\n"
     ]
    }
   ],
   "source": [
    "X = housing.drop(['SalePrice','DateSold'],axis=1) # Features\n",
    "y = housing['SalePrice']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create transformers\n",
    "#numeric_transformer = Pipeline(steps=[\n",
    "#    ('imputer', SimpleImputer(strategy='median')),\n",
    "#    ('scaler', StandardScaler())])\n",
    "#\n",
    "#categorical_transformer = Pipeline(steps=[\n",
    "#    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#        ('num', numeric_transformer, numerical_features),\n",
    "#        ('cat', categorical_transformer, cat_nom_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "#pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                           ('classifier', GradientBoostingRegressor(random_state=42))])\n",
    "\n",
    "# Preprocessing of training data and train model\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "   \n",
    "# Calculate RMSE for this fold\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#print(r2)\n",
    "# Compute the R^2 scores\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "# Print average R^2 score\n",
    "print(f\"\\nAverage R^2 Score across the 5 folds: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7042259e-c7b6-435d-aeb6-c518bb2264c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 23328 candidates, totalling 69984 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     17\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 5, 6, 7],\n",
    "    'min_weight_fraction_leaf': [0, 0.25, 0.5],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'alpha': [0, 0.5, 0.9]\n",
    "}\n",
    "#['alpha', 'ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', \n",
    "# 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', \n",
    "# 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'random_state', 'subsample', \n",
    "# 'tol', 'validation_fraction', 'verbose', 'warm_start']\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4b6b95b-7f6d-4774-a908-754af5404f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('data/CharlotteX.csv', index=False)\n",
    "#y.to_csv('data/y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d595a45-6f84-44dd-96f8-041fb4bd3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471942074680881\n",
      "\n",
      "Average R^2 Score across the 5 folds: 0.9400\n"
     ]
    }
   ],
   "source": [
    "#My best hyperparameters: {'alpha': 0.5, 'max_depth': 5, 'min_weight_fraction_leaf': 0, 'subsample': 0.8}\n",
    "#0.9219231402135216\n",
    "#Best hyperparameters: {'alpha': 0.5, 'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 1, \n",
    "#'min_samples_split': 10, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.7}\n",
    "#0.9279361418087255\n",
    "new_param = {\n",
    "    'max_depth': 3,\n",
    "    'min_weight_fraction_leaf': 0,\n",
    "    'n_estimators': 4000,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 1,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.7,\n",
    "    'alpha': 0.5\n",
    "}\n",
    "\n",
    "nick_param = {\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 6000,\n",
    "    'min_samples_split': 5,\n",
    "    'learning_rate': 0.008,\n",
    "    'subsample': 0.3\n",
    "}\n",
    "#Nicks 1st: n_estimators=10100, max_depth=4, learning_rate=0.01,min_samples_leaf=1, subsample=0.5, random_state=42\n",
    "#Nicks best: learning_rate=0.008, max_depth=3, min_samples_split=5, n_estimators=6000, subsample=0.3\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#model = GradientBoostingRegressor(**grid_search.best_params_)\n",
    "model = GradientBoostingRegressor(**nick_param)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(r2)\n",
    "# Compute the R^2 scores\n",
    "scores = cross_val_score(GradientBoostingRegressor(**nick_param, random_state=42), X_train, y_train, cv=5, scoring='r2')\n",
    "# Print average R^2 score\n",
    "print(f\"\\nAverage R^2 Score across the 5 folds: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3aadd12a-26f1-4596-a4dc-42d025783291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Importance\n",
      "77        TotalSF        0.36\n",
      "16    OverallQual        0.26\n",
      "76            Age        0.03\n",
      "0       GrLivArea        0.02\n",
      "28       BsmtQual        0.02\n",
      "32     BsmtFinSF1        0.02\n",
      "46    KitchenQual        0.02\n",
      "4         LotArea        0.02\n",
      "18   YearRemodAdd        0.02\n",
      "24     MasVnrArea        0.02\n",
      "54     GarageArea        0.02\n",
      "53     GarageCars        0.01\n",
      "11   Neighborhood        0.01\n",
      "36    TotalBsmtSF        0.01\n",
      "35      BsmtUnfSF        0.01\n",
      "71  SaleCondition        0.01\n",
      "17    OverallCond        0.01\n",
      "48     Fireplaces        0.01\n",
      "41       1stFlrSF        0.01\n",
      "25      ExterQual        0.01\n",
      "3     LotFrontage        0.01\n",
      "51    GarageYrBlt        0.01\n",
      "42       2ndFlrSF        0.01\n",
      "62    ScreenPorch        0.01\n",
      "73  DistanceToISU        0.00\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee13340-2f6f-449a-8fd2-79c1301b9dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
